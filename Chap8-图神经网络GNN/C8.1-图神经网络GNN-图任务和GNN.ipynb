{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chap8：图神经网络GNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 19:31:35.824241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 19:31:35.957418: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-18 19:31:35.987681: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-18 19:31:36.663387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/envs/tensorflow/lib/\n",
      "2023-07-18 19:31:36.663457: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/envs/tensorflow/lib/\n",
      "2023-07-18 19:31:36.663463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from source.code import ch8\n",
    "from source.code import utils \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你要在服务器上和别人共用GPU，可以设置你需要的显存资源\n",
    "utils.gpu_limitation_config(memory=30,device=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.1 图任务和GNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.1.1 图数据和图任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了图像和文本之外，另外一种随着互联网技术发展成熟起来，不断扩展和丰富的**非结构化**数据是**图数据**（**Graph Data**），图数据主要**由节点（样本个体）、边（个体间的连接关系），及节点上的特征和边上的特征组成**，例如：\n",
    "* 在一个通信软件 / 平台上（微信、支付宝、通讯录），每个用户视为节点，好友关系视为边，这就构成了最简单的好友图网络\n",
    "* 在社交媒体平台上，每个用户可以视为节点，**A 关注 B 可以视为从 A 到 B 的有向边**，这构成了一个带方向的社交图网络\n",
    "* 在论文数据集中，每一篇论文可以视为节点，**论文间的引用关系可以视为边**，这构成了一个论文引用关系图网络"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在很多机器学习建模问题中，**物以类聚，人以群分**的思想普遍通用，**图数据就为我们提供了一种天然的聚集结构**，借助图的结构，我们能够从这些连接关系中挖掘出更多有价值的信息\n",
    "* 例如**欺诈团伙经常有转账交易**，以转账关系建立起来的图网络能够整体挖掘出欺诈团伙，**这比单独依据每个欺诈个体的特征来识别黑户会更加有效**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先介绍图数据的分类和构成，然后介绍有关于图数据的几种常见的目标任务"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8.1.1.1 图数据**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 静态同构图**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/静态同构图.png\" width=250>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "静态同构图是最常见，最简单的一种图数据，我们用 $\\mathcal{G}=\\{\\mathcal{N}, \\mathcal{E}, \\mathcal{N}_f, \\mathcal{E}_f\\}$ 表示图数据，其中：\n",
    "* $\\mathcal{N}$ 表示节点集合，例如 $\\mathcal{N} = \\{n_1,n_2,\\cdots,n_N\\}$，在**同构图中，我们要求所有的节点属于同一类型实体**\n",
    "  * 图中连接关系多样，在有的图中，可能是不同类型的两个实体具有连接关系，例如**银行-个人**，**学校-学生**等，在这些连接关系中，涉及到两种及以上不同类型实体的连接关系，**这不是同构图所考虑的范畴**，同构图要求所有节点都可以抽象为同一类型的实体\n",
    "* $\\mathcal{E}$ 表示边集合，边集合**可以用邻接矩阵或哈希表**来存储\n",
    "  * 如果图**边的连接比较稠密**，则使用 0-1 的邻接矩阵是个不错的选择\n",
    "    ```python\n",
    "    # 使用 01 邻接矩阵\n",
    "    edges = [[0, 0, 1, 1, 0, 1],\n",
    "             [0, 0, 1, 0, 1, 1],\n",
    "             [1, 1, 0, 0, 0, 0],\n",
    "             [1, 0, 0, 0, 0, 1],\n",
    "             [0, 1, 0, 0, 0, 1],\n",
    "             [1, 1, 0, 1, 1, 0]]\n",
    "    ```\n",
    "  * 如果图**边的链接比较稀疏**，则**使用哈希表存储每个节点的邻居节点可以节省内存空间**：\n",
    "    ```python\n",
    "    # 使用哈希表\n",
    "    edges = {\n",
    "      0: [2, 3, 5],\n",
    "      1: [2, 4, 5],\n",
    "      2: [0, 1],\n",
    "      3: [0, 5],\n",
    "      4: [1, 5],\n",
    "      5: [0, 1, 3, 4]\n",
    "    }\n",
    "* $\\mathcal{N}_f$ 表示**节点特征**，每个节点 $n_i$ 可以拥有自己的一组特征 $n_i^{(f)}\\in\\mathbb{R}^{p}$\n",
    "  * 例如在社交图中，每个账户作为节点，则账户个体的年龄、性别、注册时长、活跃度等信息就可以作为节点特征\n",
    "  * 例如在论文引用图中，每篇论文作为节点，则论文的字数、学科类别、发表期刊、发表年份等信息可以作为节点特征\n",
    "* $\\mathcal{E}_f$ 表示**边特征**，每条图中存在的边 $e_{i,j}\\in\\mathcal{E}$ 可以拥有自己的一组特征 $e_{i,j}^{(f)}\\in\\mathbb{R}^q$\n",
    "  * 例如在社交图中，用户 A 关注 B 成为一条边，则 A 对 B 的评论数、点赞数、转发数等信息可以作为边特征\n",
    "  * 例如在微信 / 支付宝好友网络图中，A 和 B 之间的转账次数、转账金额等信息就可以作为边特征"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 静态异构图**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/静态异构图.png\" width=300>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果**解除同构图中对节点属于同一类型实体的限制**，我们就得到了**异构图**，此时**节点集合可以根据实体类型划分为多个组** $\\mathcal{N} = \\mathcal{N}_1 \\cup \\mathcal{N}_2\\cup\\cdots\\cup \\mathcal{N}_k$\n",
    "* 例如在**公司-员工**图网络中，所有公司可以构成节点集合 $\\mathcal{N}_1$，所有员工构成节点集合 $\\mathcal{N_2}$\n",
    "  * 根据**任职关系**，**员工先与自己所在的公司相连**\n",
    "  * 根据**公司的合作关系 / 投资关系**，公司之间又可以相连\n",
    "* 由于节点类型不同，异构图中，**不同类型的节点可以拥有不同类型的特征**，同样，不同类型节点之间的连接边特征也可以有不同的表示\n",
    "  * 例如员工作为节点有属于自己的特征向量（例如员工年龄，性别），公司节点有另一套特征向量（例如公司规模、公司人数、公司类型）\n",
    "  * 员工与公司连接的边特征（例如工资，职级），和公司之间的边征也可以使用不同含义的特征向量（例如投资金额、合作类型）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 动态图**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/动态图.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在更复杂的场景中，**图上的信息会随着时间发生变化**，此时我们就需要引入动态图 $\\mathcal{G}(t)=\\{\\mathcal{N}(t), \\mathcal{E}(t), \\mathcal{N}_f(t), \\mathcal{E}_f(t)\\}$\n",
    "* 通常，我们会选择某一**观察时间点** $t$ 及**时间窗口** $T$，**统计过去一段时间以来所有连接关系构成的图** $\\mathcal{G}(t)$\n",
    "  * 这可以称为在时间 $t$ 时，**图结构的一个快照** $\\mathcal{G}(t)$\n",
    "  * 例如在社交平台中，我们可以**按周 / 月的频率来构建每周 / 每月的社交图网络**，即统计过去一周 / 一个月用户的关注、点赞、转发、评论等数据的汇总信息，构建出当前观察时间的图网络\n",
    "* 动态图能够**捕获图结构中的变化趋势，趋势信息的加入能够进一步从数据中挖掘有效信息**\n",
    "  * 例如欺诈团伙时别中，我们能够在动态图中捕捉到欺诈团伙的状大，资金流的规模和广度增大成为交易网络中的异常点，这些趋势可以被模型抓取"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们简单说明图数据中**跳数**和**k-跳**的概念\n",
    "* **与节点直接相连**的邻居被称为 **1-跳** 邻居节点\n",
    "* 间接相连的节点需要大于 1 次跳跃才能建立连接关系，**k-跳** 即指需要至少 $k$ 次跳跃才能建立连接\n",
    "* 如果节点 $A$ 到节点 $B$ 有多条路径可达，则**取最短路径长度作为** $A,B$ **之间的跳数**\n",
    "\n",
    "在后续大部分的讨论中，我们只考虑**1-跳问题**，即**只考虑与节点直接相连的邻居**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8.1.1.2 图任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图数据的预测任务大致可以分为**节点级任务**，**边级任务**和**全局图任务**三类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 节点级任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "节点级任务是最常见最广泛的一类图预测任务，我们需要借助图的信息，提升模型对每个节点个体的预测准确度，即对节点集合 $\\mathcal{N}$ 中的每个节点 $n_i$ 做出判别\n",
    "* 例如在欺诈团伙识别中，我们需要判断每个个体账户是否是黑户，这是一个 **0-1 二分类问题**\n",
    "* 在物流图网络中，我们可能需要预测每个城市节点的流量，这是一个**回归问题**\n",
    "* 有时候我们面对的是**无标签的图结构数据**，但我们可以**通过聚类模型来完成对图中节点的分类**\n",
    "* **如果我们丢弃图结构信息，则可以仅利用每个节点自己的节点特征向量构建模型**，完成节点预测任务，但往往图结构信息的加入能够提升模型性能"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 边级预测**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "边级任务需要**判断图中两个节点是否具有关联关系，或者其关联关系的强弱**，即对边集合 $\\mathcal{E}$ 中的每条边 $e_{i,j}$，或者对没有在边真实图中的边集 $\\mathcal{E}$ 的两个节点的连接 $e_{i,j}$ 做出判别\n",
    "* 给定图中的两个节点 $A,B$，如果任务是**判断节点是否有关联关系**，则需要做出预测 $e_{A,B}\\in\\{0,1\\}$，这是一个 **0-1 二分类问题**\n",
    "  * 例如在一个社交图网络中，如果模型预测 $e_{A,B} = 1$，则 $A,B$ 可能是认识的人，又或者是 $B$ 可能是 $A$ 关注人群中的一员，这时系统就可以将 $B$ 推荐给 $A$（例如各社交媒体平台中**可能认识的人**，**可能感兴趣的人**）等，成为推荐系统应用的一部分\n",
    "* 给定图中的两个节点 $A,B$，如果任务是**判断节点之间的相似度 / 相关性**，则可以通过规范化做出预测 $e_{A,B}\\in(0,1)$，这是一个 **回归问题**\n",
    "  * 例如在**论文引用 / 论文相似性图网络**中，边的权重作为相关性的度量，则通过**预测论文之间边的相关性**，当给定论文节点 $A$ 时，预测给定集合 $\\mathcal{S}=\\{B_1,\\cdots,B_m\\}$ 中每一篇论文 $B_j$ 与 $A$ 的相关性\n",
    "    * 可以利用相关性排序，制作一个相关论文的推荐系统，帮助学者快速找到所需要的论文资料，而无需大海捞针\n",
    "    * 或者利用这种图网络和边的相似性，来设计论文抄袭检测算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 全局图任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在全局图任务中，我们的目标是对整个图 $\\mathcal{G}$ 的性质做出判别\n",
    "* 例如，在化学药学领域，可以**将每个原子视为节点，所有的原子根据化学结构的连接关系构成分子**，一个分子就是一个完整的图\n",
    "  * 更改分子结构，会改变分子的化学性质\n",
    "  * 想要**对分子的性质做出预测就是一全局图预测任务**，例如预测新化学式分子是否有毒，或者是否有疗效，这是**对全局图的分类问题**\n",
    "* 又例如，一些全局图任务关注在**图中是否存在环结构**，或者预测整张图中环结构的数量\n",
    "* 又例如，在一些应用中，人们会把**图像 / 文本样本抽象为一个图**，则原本的图像分类 / 文本分类任务就可以看作是一个全局图任务"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.1.2 图神经网络**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图神经网络**（**Graph Neural Network**，**GNN**）与之前介绍的 CNN，RNN 类似，目标都是**在处理非结构化数据中作为特征提取器**，通过精巧的模型设计，得到非结构化数据的**特征编码向量**（即利用神经网络获得**表征**），最终我们**将这些向量作为全连接网络的输入，用于下游任务**，在一个图任务中，我们可以编码的对象有三种：\n",
    "* **节点**：通过 GNN，用一个 $\\mathbb{R}^p$ 向量作为图中的每个节点的表征\n",
    "* **边**：通过 GNN，用一个 $\\mathbb{R}^p$ 向量作为图中每条边的表征\n",
    "* **全局图**：通过 GNN，我们还能汇总所有的节点信息和边信息，得到一个 $\\mathbb{R}^p$ 的全局图表征向量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再介绍 GNN 建模思想之前，首先需要解决的是**图数据的表示问题**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **图数据的表示**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习建模任务中，我们需要**将输入数据转换为张量 / 多维数组的形式存储**，要将图数据转换为张量表示，会遇到一些新的困难，我们具体来看\n",
    "* 节点特征的表示是直接的，我们可以给每个节点分配一个索引 $i$，每个节点对应的特征为 $n_i^{(f)}\\in\\mathbb{R}^p$，则我们可以用 $V\\in\\mathbb{R}^{N\\times p}$ 来存储节点特征\n",
    "* 图的连接关系和边的特征存储就具有技巧性了，**邻接矩阵虽然可以直观地表示图中节点的连接关系，但它会有两个问题**：\n",
    "  * 第一：对于实际场景中的大部分图，**节点的连接都是稀疏的**，这意味着用邻接矩阵保存图结构将会得到一个巨大的稀疏矩阵，这浪费内存和性能（此时的存储规模需要 $\\mathcal{O}(N^2)$）\n",
    "  * 第二：邻接矩阵**不具有置换不变性**，即对于同一张图，如果交换节点的索引排序（即对节点顺序做一次置换），**则会得到完全不同的邻接矩阵**，此时，**多个不同的领结矩阵却对应的图结构中相同的连接关系**，我们却很难保证基于不同的邻接矩阵输入 $M$，得到相同的模型输出 $f(M)$\n",
    "* 因此，一种更适用的连接关系和边特征的存储方式是将节点 $n_i,n_j$ 的**连接关系存储为一个元组**，假设有一条从 $n_j$ 指向 $n_i$ 的边，则用元祖 $(i,j)$ 来表示这条边，然后我们**用邻接列表来存储这些元素**，同时，在**用相同索引映射的张量来存储这些边上的特征**，记为张量 $E\\in\\mathbb{R}^{M\\times p}$，例如：\n",
    "  ```python\n",
    "  # 邻接列表\n",
    "  edges = [[1, 0],\n",
    "           [2, 0],\n",
    "           [3, 4],\n",
    "           [6, 2],\n",
    "           [7, 1],\n",
    "           [7, 3]]\n",
    "  # 边特征，这里假设特征是 5 维的离散特征\n",
    "  edges_feats = [\n",
    "      [0, 1, 1, 0, 1],\n",
    "      [1, 0, 1, 1, 0],\n",
    "      [1, 1, 0, 1, 0],\n",
    "      [0, 1, 1, 0, 1],\n",
    "      [1, 0, 0, 1, 0],\n",
    "      [1, 0, 0, 1, 0]\n",
    "  ]\n",
    "  ```\n",
    "  * 通常，邻接列表会按照**入-出节点的索引顺序**升序排列，这可以方便我们快速定位以 $i$ 为入节点的所有的边\n",
    "  * 在一个稀疏的图中，上述存储方案能够**大大降低内存消耗**，不再需要一个 $\\mathcal{O}(N^2)$ 的存储\n",
    "* **全局图特征**的表示，也可以使用一个 $\\mathbb{R}^p$ 的向量存储，我们用张量 $U\\in\\mathbb{R}^{O\\times p}$ 存储这些特征，其中 $O$ 表示图数据中图的个数（**在一些图数据中，完整的图数据由多个图构成**）\n",
    "  * 例如多个化学式分子，没个化学分子就构成一张图\n",
    "* 在有的任务中，**节点或者边只有其索引，而没有特征表示**，但我们依然想获得有关它们的稠密表示，此时可以**借助 NLP 中处理词元的思想**，我们可以**用嵌入层** `Embedding` 先讲离散索引映射到 $\\mathbb{R}^p$ 稠密向量，再做后续的特征计算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 CNN 和 RNN 一样，在设计 GNN 之前，我们需要对模型所具有的性质做出假设，例如 **CNN 的局部性和平移等变形**，**RNN 的** $H_t = f(X_t,H_{t-1})$，通常情况下，**GNN 需要满足下面两条性质**：\n",
    "* **GNN 算子不改变图结构**，其特点满足**Graph-in，Graph-out**，GNN 算子应该以图结构数据为输入，然后返回相同结构的图输出（包含节点特征、边特征、连接关系、全局图特征），GNN 算子应该**只加工和改变这些图信息的嵌入向量 / 特征表示**\n",
    "* **GNN 算子应该具有图对称性 / 置换不变性**，即 GNN **算子的运算结果与节点在图表示中的顺序是无关的**\n",
    "  * 假设我们有两个节点输入 $n_i,n_j$，其特征表示分别为 $x_i,x_j$，则：\n",
    "    * 平均汇聚就是一种具有置换不变形的算子，因为它的计算结果与节点索引顺序无关：\n",
    "        $$\n",
    "        f(x_i,x_j) = \\frac{1}{2} (x_i + x_j)\n",
    "        $$\n",
    "    * 带有两个权重参数 $W_1,W_2$ 的 MLP 变换就不具有置换不变的特点，因为计算结果与 $x_i,x_j$ 的顺序有关：\n",
    "        $$\n",
    "        f(x_i,x_j) = W_1 x_i + W_2 x_j\n",
    "        $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 最简单的 GNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们沿用刚才对节点、边和全局图特征的表示 $V,E,U$，现在能够讨论如何构建 GNN 了，一种最简单的方法是，我们**暂时丢掉图结构信息**，仅通过三个 MLP 来获得每个部分的特征表示，如下图所示：\n",
    "* $U_n, V_n, E_n$ 是第 $n$ 层 GNN 的输入\n",
    "* 通过**三个 MLP 变换** $f_{U_n}, f_{V_n}, f_{E_n}$ 分别将 $U_n, V_n, E_n$ 映射到下一层 $U_{n+1}, V_{n+1}, E_{n+1}$，它们共同称为**一个 GNN 层**\n",
    "* 对于节点、边和全局图，经过一层 GNN 层后，我们会**更新它们的嵌入表示 / 特征表达**，**每一层 GNN 只改变这些图信息的 embedding，不会改变图结构**\n",
    "* 与 MLP，CNN 和 RNN 一样，由于 **GNN 层不改变图的连接结构**，**GNN 层可以堆叠，得到深度 / 多层的 GNN 特征提取器**\n",
    "* **最后一层 GNN 的 embedding 输出，可以作为下游任务模型的输入**，从而完成节点级别、边级别、全局图级别的不同任务"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/最简单的GNN.jpg\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 通过信息汇聚（Pooling）进行预测**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于给定的任务，我们可以非常方便的**将 GNN 特征提取器得到的特征表达作为下游任务的输入，搭建一个端对端的模型**\n",
    "* 以节点级任务为例，我们将最后一层 GNN 关于节点特征表达的输出 $V_n$ 作为下游任务网络 $C_{V}$（例如一个 MLP），就可以实现关于节点的预测任务了\n",
    "* 上述方案可以非常简单地**推广到边的预测任务，或者全图的预测任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/节点任务.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但有时候，情况会糟糕一些，例如：\n",
    "* 我们在**进行节点预测时，可能会没有节点特征**，即图中**所有的特征信息都只保存在边上**\n",
    "* 或者在**进行边预测时，没有关于边的特征**，图中的**所有特征都保存在节点上**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时，我们可以通过深度学习中常见的**汇聚（pooling）操作**，来解决上面存在的困难，汇聚大概分为两步：\n",
    "* **第一步**：将要汇聚的特征表达，即 embedding 向量进行**拼接**，成为一个张量\n",
    "* **第二步**：通过**聚合函数**，通常是**求和或均值**，汇聚得到新的 embedding 表达"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将所有的汇聚算子用字母 $\\rho$ 表示，用 $\\rho_{E_n\\to V_n}$ 表示将**边上的信息汇聚到节点**，如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/将边上的信息汇聚到节点.png\" width=800>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设某个节点 $n_i$ 具有特征向量 $n_i^{(f)}\\in\\mathbb{R}^p$（**或者没有特征向量**），**以它为入节点的相连的边集合**为 $E_{n_i}$，每条边 $e\\in E_{n_i}$ 拥有特征表达 $e^{(f)}\\in\\mathbb{R}^p$，则汇聚算子 $\\rho_{E_n\\to V_n}$：\n",
    "$$\n",
    "\\rho_{E_n\\to V_n} (n_i) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        n_i^{(f)} + \\sum_{e\\in E_{n_i}} e^{(f)} & ,\\text{节点存在特征向量} \\\\\n",
    "        \\sum_{e\\in E_{n_i}} e^{(f)} & ,\\text{节点没有特征向量} \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，在**缺少节点特征向量时，我们可以通过从边特征汇聚的方法来完成之前的预测任务**，如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/借助边特征完成节点预测.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述汇聚的思路也完全可以反过来，用 $\\rho_{V_n\\to E_n}$ 表示将**节点的信息汇聚到边上**，假设某条边 $e_{i,j}$ 具有特征向量 $e_{i,j}^{(f)}\\in\\mathbb{R}^p$（**或者没有特征向量**），**它所连接的两个节点为**为 $n_i,n_j$，具有特征向量 $n_i^{(f)},n_j^{(f)}\\in \\mathbb{R}^p$，则汇聚算子 $\\rho_{V_n\\to E_n}$：\n",
    "$$\n",
    "\\rho_{V_n\\to E_n} (e_{i,j}) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        e_{i,j}^{(f)} + n_i^{(f)} + n_j^{(f)} & ,\\text{边存在特征向量} \\\\\n",
    "        n_i^{(f)} + n_j^{(f)} & ,\\text{边没有特征向量} \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，在**缺少边特征向量时，我们可以通过从节点特征汇聚的方法来完成之前的预测任务**，如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/借助节点特征完成边预测.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全图预测也可以用相同的思想推广，例如我们**将节点特征汇聚到全图特征**，用算子 $\\rho_{V_n\\to U_n}$ 表示该汇聚过程，则这很像 **CNN 中的全局平均汇聚层**，如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/借助节点特征完成全图预测.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以将整个 GNN 模型的计算图抽象为下面的形式：\n",
    "* 图数据先经过**多层的 GNN 算子提取节点、边、全图的特征表达**\n",
    "* 根据具体任务，使用相应的**特征表达作为下游网络的输入（例如分类器）**，构造**端对端模型**\n",
    "* 如果**缺少相应的特征表达，则可以通过汇聚的方式来抽取特征**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/端对端GNN.png\" width=1100>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 在 GNN 层中通过汇聚传递信息**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前为止，我们都**没有在 GNN 层中使用图结构信息**，图中的节点、边和全局图特征提取和加工在 GNN 层中是独立进行的，我们仅说明了**在预测时利用图中的连接关系进行特征汇聚**，但预测时的这种汇聚思想可以非常简单地推广到 GNN 层中"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了**在 GNN 层提取特征时充分使用图的连接关系**，我们可以**让邻居节点、以及连接节点的边交换信息**，从而**作用到它们 embedding 向量的更新**，这一过程称为**信息传输**（**Meaasge Passing**），通常可以拆解为三个步骤：\n",
    "* **第一步**：对于图中的每个节点，收集所有其邻居节点的 embedding 特征表达（即信息）\n",
    "* **第二步**：通过一个聚合函数将所有信息聚合为一个向量，例如求和\n",
    "* **第三步**：汇聚的信息通过一个神经网络来学习新的特征表达，例如一个 MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/GNN层中节点信息传递.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息传输除了可以作用在节点，也可以类似地推广到边特征的更新上，**上述这些步骤是利用图的连接关系的关键**。我们可以**在 GNN 层中构建更精细的信息传输变体**，以得到具有**更强特征抽取能力**的 GNN 模型\n",
    "* 当把如上一系列的计算过程应用一次时，就得到了一个最简单的 **GNN 信息传输层**\n",
    "* 这种特征抽取模式**与处理图像时的标准卷积运算非常相似**，信息传递和卷积都通过聚合周围元素的信息来进行信息更新\n",
    "  * **相似的是**，在 CNN 中，传递信息的是周围的像素，而在 GNN 中，传递信息的是周围邻居节点\n",
    "  * **不同的是**，在 CNN 中，一个像素的邻居像素数量是固定的，但在 GNN 中，每个节点的邻居节点数量灵活多变\n",
    "* 与 CNN 类似，通过**将 GNN 消息传递层堆叠**，节点**最终可以汇聚整个图中的信息**（回顾 CNN 中**感受野**的概念）\n",
    "  * 在 $k$ **层之后，每个节点拥有离它** $k$**-跳的节点的信息**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将上述**节点信息传递的算子记为** $\\rho_{V_n\\to V_n}$，则具有信息传递的 GNN 层的新架构可以用下图表示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/具有信息传递的GNN层.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然在 GNN 信息传递层的设计中，我们也可以**让节点特征、边特征、全局图特征进行交互**\n",
    "* 除了将邻居节点的信息传递给节点，还可以**将与节点相连的边特征传递给节点**，与之前的过程类似，我们先将边特征做汇聚，然后让其通过一个神经网络 $f$ 学习新的特征表达做转换，最后保存新的特征向量\n",
    "* 当然，**节点和边的特征维度可能不一致，所以无法直接相加汇聚，此时可以通过** $f$ **调整维度达成统一**（例如更改全连接层的输出维度），另一种解决思路是**将它们的特征向量拼接，变成一个更长的向量**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如一种结合节点和边的信息传递策略如下图所示：\n",
    "* 首先通过 $\\rho_{V_n\\to E_n}$ **将节点的信息汇聚到连接它们的边上**，并保存汇聚信息 $E_{pooled}$\n",
    "* 然后，**再将边上汇聚信息** $E_{pooled}$ **通过** $\\rho_{E_n\\to V_n}$ **传递汇聚到节点上**，得到汇聚信息 $V_{pooled}$\n",
    "* 节点和边的汇聚信息 $V_{pooled}, E_{pooled}$ 分别通过神经网络 $f_{V_n},f_{E_n}$ **学习新的特征表达**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/节点和边的特征汇聚.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，如何**设计信息传递的顺序、方案是 GNN 信息传递曾设计的决策环节之一**，对于四种传递和汇聚方案（**节点到节点，边到边，节点到边，边到节点**）可以按不同的顺序灵活组合，如下图所示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/灵活组合信息传递方案.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上述的 GNN 消息传递层中，存在一个缺陷，即**相距较远的两个节点需要经过多个层才能进行通信**：\n",
    "* 对于**给定的 GNN 层数，相距遥远的节点也可能永远无法有效地相互传递信息**\n",
    "* 如果预测任务依赖于相距很远的节点或节点组的情况，这可能会影响模型预测"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种解决方案是**增加 GNN 层数，或者设计结构让所有的节点都能通信并传递信息**，但对于大型图而言，**昂贵的计算代价**会使得计算变得不可行"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一种简单的解决方案，是**在信息传递中加入全局图特征**，这时候**全局图特征可以抽象为图中的一个主节点 / 全局节点**（**master node**），如下图所示：\n",
    "* 这个主节点**连接了图中的每一个节点和图中每一条边**\n",
    "* 主节点可以充当节点、边的**桥梁**，**帮助它们传递信息**\n",
    "* 主节点在模型训练学习过程中，**可以学习到更丰富、更复杂的全局图表示**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/全局图信息的加入.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，在考虑图中节点、边、全局图的特征表达学习时，我们可以**在汇聚信息的过程中通过将感兴趣的信息与其它信息进行比较然后来利用它们，这通常通过设计不同的特征提取和汇聚机制** $cond(x|z)$ **来实现**，如下图所示\n",
    "* 例如，对于一个节点，我们可以考虑来自相邻节点、相邻边和全局信息的信息做汇聚，汇聚时可行的方案也有很多：\n",
    "  * 通过 MLP 将特征变换到相同形状，然后相加聚合\n",
    "  * 通过拼接得到一个很长的特征向量，然后传递给 MLP 变换回原来的特征维度\n",
    "  * 或者**在汇聚时使用注意力机制**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/GNN特征汇聚机制.png\" width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这一节只**介绍了 GNN 模型的设计思想**，而没有具体说明某个 GNN 模型的计算过程，这将在后面的章节中详细讨论"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.1.3 GNN 数据准备**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以 `Cora` 数据集为例，展示图数据的预处理流程，`Cora` 数据集是 GNN 的经典数据集之一，它**包含来自机器学习论文的引用网络**，这些论文被分为**七个类别**（例如遗传算法、神经网络、概率方法、强化学习等），数据集存放在路径 `../source/data/graph/cora/`\n",
    "\n",
    "* 数据集包含 2708 个节点（2708篇论文），5429 条边（5429条引用关系）\n",
    "* 文件目录如下：\n",
    "  * `cora`\n",
    "    * `cora.content`\n",
    "      * 保存了节点信息，**每一行是一个 1435 维的向量**，用 `\\t` 分割\n",
    "      * 第一个是节点编号，中间 1433 个是节点特征，最后一个是节点类别\n",
    "      * 1433 维的节点特征**是 0-1 的独热编码**，对应 **1433 个论文词表词元**，如果该节点对应的论文中包含了该词元，则对应词元的向量取值为 1， 否则为 0\n",
    "    * `cora.cites`\n",
    "      * 保存了论文引用关系，即节点连接关系，格式为 `node1 node2`，中间用 `\\t` 分割\n",
    "      * `node1 node2` 表示 `node2` 引用 `node1`，即**前面的节点是被引用节点**\n",
    "      * 通常在图数据中，**被指向的节点放在边关系的前面**\n",
    "* 数据集中有一些论文**没有被引用**，相当于**没有指向它们的节点，它们只会指向其它节点**\n",
    "  * 数据集的 2708 篇论文中，有 1565 篇论文包含被引用关系\n",
    "  * 通常来说，**包含被引用论文的节点可以借助连接关系传递信息**，而没有被引用的论文节点，从有向图的角度来看，可以认为是”**孤立的**“\n",
    "  * 当然，我们也可以把这种引用关系**扩宽到无向边关系**，则**引用关系成为了一种对称的相互关系**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数 `load_cora` 读取数据集文件，并读取节点信息和边信息，然后创建一个字典 `vertex_edge_loc` **用于快速索引每个节点的邻居**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora(path : str):\n",
    "    import os\n",
    "    # 读取节点信息\n",
    "    vertex, vertex_feat, vertex_class = [], [], []\n",
    "    class_map = {} # 记录类别和类别索引\n",
    "\n",
    "    with open(os.path.join(path, 'cora.content'), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split('\\t')\n",
    "            # 获取节点编号、节点特征、节点类别\n",
    "            node, feat, label = int(line[0]), line[1:-1], line[-1]\n",
    "            feat = [int(x) for x in feat]\n",
    "\n",
    "            if label not in class_map:\n",
    "                class_map[label] = len(class_map)\n",
    "            \n",
    "            vertex.append(node)\n",
    "            vertex_feat.append(feat)\n",
    "            vertex_class.append(class_map[label])\n",
    "    \n",
    "    # 读取边信息\n",
    "    edges = []\n",
    "\n",
    "    with open(os.path.join(path, 'cora.cites'), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split('\\t')\n",
    "            # 获取边的两个节点编号\n",
    "            node1, node2 = int(line[0]), int(line[1])\n",
    "            # 三元组用于存储边信息，(node1, node2, 边特征)\n",
    "            # [0] 表示边的特征，这里没有边的特征\n",
    "            edges.append((node1, node2, [0]))\n",
    "\n",
    "    return vertex, vertex_feat, vertex_class, edges, class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数： 2708\n",
      "边数： 5429\n",
      "类别数： 7\n",
      "类别： dict_keys(['Neural_Networks', 'Rule_Learning', 'Reinforcement_Learning', 'Probabilistic_Methods', 'Theory', 'Genetic_Algorithms', 'Case_Based'])\n"
     ]
    }
   ],
   "source": [
    "# 读取 cora 数据集\n",
    "vertex, vertex_feat, vertex_class, edges, class_map = ch8.load_cora('../source/data/graph/cora/')\n",
    "print('节点数：', len(vertex))\n",
    "print('边数：', len(edges))\n",
    "print('类别数：', len(class_map))\n",
    "print(\"类别：\", class_map.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以查看每个类别的节点数量，可以观察到七种类别是不平衡的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    818\n",
       "3    426\n",
       "5    418\n",
       "4    351\n",
       "6    298\n",
       "2    217\n",
       "1    180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每个类别的节点数量\n",
    "pd.Series(vertex_class).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，当**给定某个节点 `v` 时，我们希望快速定位到节点 `v` 相连接的边**\n",
    "* 下面的函数 `compute_vertex_edge_loc()` 将图中的边按照 `node1` 的顺序进行重新排序\n",
    "* 然后用字典 `vertex_edge_loc` 来保存每个有边相连的节点，其所连接的边在列表 `edges` 中的起始位置\n",
    "* 这样当给定节点 `v` 时，`edges[vertex_edge_loc[v][0]:vertex_edge_loc[v][1]]` 就取出了与 `v` 想连的边信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vertex_edge_loc(vertex, edges):\n",
    "    \"\"\"\n",
    "    ### 计算每个节点邻居边的起始位置\n",
    "        重新将边 `edges` 按照节点名称排序，然后计算每个节点邻居边的在 edges 中的起始位置 `vertex_edge_loc`\\n\n",
    "        这样当给定节点 `v` 时，可以通过 `vertex_edge_loc[v]` 得到 `v` 的邻居边在 `edges` 中的起始位置\\n\n",
    "    \"\"\"\n",
    "\n",
    "    # 对边进行排序\n",
    "    # 先按照 node1 排序，再按照 node2 排序\n",
    "    edges = sorted(edges, key=lambda x: (x[0], x[1]))\n",
    "    \n",
    "    # 记录每个节点边的起始位置，以便于快速查询\n",
    "    # 默认值为 [-1, -1]，表示该节点没有邻居边\n",
    "    vertex_edge_loc = {node : [-1,-1] for node in vertex}\n",
    "    for i, edge in enumerate(edges):\n",
    "        if vertex_edge_loc[edge[0]][0] == -1:\n",
    "            vertex_edge_loc[edge[0]][0] = i\n",
    "        vertex_edge_loc[edge[0]][1] = i + 1\n",
    "    \n",
    "    return edges, vertex_edge_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_edge_loc[0]： [2706, 2709]\n",
      "vertex[0]： 31336\n",
      "vertex[0] 的邻居边： [(31336, 31349, [0]), (31336, 686532, [0]), (31336, 1129442, [0])]\n"
     ]
    }
   ],
   "source": [
    "edges, vertex_edge_loc = ch8.compute_vertex_edge_loc(vertex, edges)\n",
    "# 例如，获得 vertex[0] 的邻居边在 edges 中的起始位置\n",
    "print(\"vertex_edge_loc[0]：\", vertex_edge_loc[vertex[0]])\n",
    "# 获取 vertex[0] 的邻居边\n",
    "start, end = vertex_edge_loc[vertex[0]]\n",
    "print(\"vertex[0]：\", vertex[0])\n",
    "print(\"vertex[0] 的邻居边：\", edges[start:end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以统计每个节点邻居个数的分布情况，可以看到**绝大部分节点的邻居个数小于 25 个**，只有极少数节点的被引用次数超过了 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fef5af044f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAEmCAYAAAAwStp9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0fklEQVR4nO3deVRV5d4H8O9hng8hwwFFxBEn0FCRVLQggcycMjVeh67DWyGaqCE3B7RuGKZ5nVdZmjezsqu2UlMQBxIRFUWUFNMQNBlMhCMoAp7n/cPFfjsiyMHNcPD7Weus5d7Pc/b+7bO1b88eFUIIASIiIpKNQWMXQERE1NwwXImIiGTGcCUiIpIZw5WIiEhmDFciIiKZMVyJiIhkxnAlIiKSGcOViIhIZkaNXYA+0Gg0uHHjBqytraFQKBq7HCIiaiRCCNy5cwcuLi4wMKh+fMpwrYUbN27A1dW1scsgIqIm4tq1a2jVqlW17QzXWrC2tgbw8Me0sbFp5GqIiKixqNVquLq6SrlQHYZrLVQeCraxsWG4EhHRE08R8oImIiIimTFciYiIZMZwJSIikhnPuRKR3nrw4AHKy8sbuwxqRgwNDWFkZPTUt10yXIlILxUXF+P69esQQjR2KdTMWFhYwNnZGSYmJnVeBsOViPTOgwcPcP36dVhYWMDBwYEPdyFZCCFQVlaGmzdvIjMzEx06dKjxQRE1YbgSkd4pLy+HEAIODg4wNzdv7HKoGTE3N4exsTGysrJQVlYGMzOzOi2HFzQRkd7iiJXqQ11Hq3/HkWsDazNvT7VtV5cOacBKiIiovnDkSkREJDOGKxGRHomKikKPHj10+s6gQYPw3nvv1dhHoVBg165dda6LtPGwMBE1GzWddqkPjXEqZ86cOQgLC2vw9eoThUKBnTt3Yvjw4Y1WA8OViEiPWFlZwcrKqrHLqJWysrKnuldUn/GwMBFRAxk0aBBmzJiB999/H3Z2dlCpVIiKitLqU1hYiClTpsDBwQE2NjZ46aWXcPbsWan90cPCFRUVmDFjBmxtbdGiRQtERERg4sSJVUZtGo2mxvUCQE5ODoKDg2Fubo62bdvixx9/1Go/d+4cXnrpJZibm6NFixaYNm0aiouLpfZJkyZh+PDh+Ne//gUXFxd06tQJALBu3Tp06NABZmZmcHJywuuvv17j75SYmIhBgwbBwsICzz33HAIDA3H79u1a/YZt2rQBAIwYMQIKhUKaPnv2LF588UVYW1vDxsYG3t7eOHXqVI11PA2GKxFRA/r6669haWmJ5ORkxMTEYMmSJYiLi5PaR48ejfz8fPzyyy9ISUnB888/D39/fxQUFDx2eZ988gm2bt2KTZs2ITExEWq1+rHnTp+0XgBYsGABRo0ahbNnzyIkJARjx47FhQsXAAAlJSUIDAzEc889h5MnT2L79u04cOAApk+frrWM+Ph4ZGRkIC4uDrt378apU6cwY8YMLFmyBBkZGdi3bx/8/Pyq/X1SU1Ph7++PLl26ICkpCUePHsXQoUPx4MGDWm3LyZMnAQCbNm1CTk6ONB0SEoJWrVrh5MmTSElJwbx582BsbFxtHU+Lh4WJiBqQp6cnFi1aBADo0KED1qxZg/j4eLz88ss4evQoTpw4gfz8fJiamgIAPv30U+zatQs//vgjpk2bVmV5q1evRmRkJEaMGAEAWLNmDfbu3avTeiuNHj0aU6ZMAQB8+OGHiIuLw+rVq7Fu3Tp8++23KC0txZYtW2BpaSmta+jQofjkk0/g5OQEALC0tMTGjRulw8E7duyApaUlXn31VVhbW8PNzQ09e/as9veJiYlBr169sG7dOmle165da70tDg4OAABbW1uoVCrpO9nZ2Zg7dy48PDyk79UnjlyJiBqQp6en1rSzszPy8/MBPDx0WVxcjBYtWkjnVq2srJCZmYkrV65UWVZRURHy8vLQp08faZ6hoSG8vb11Wm8lX1/fKtOVI9cLFy7Ay8tLClYA6NevHzQaDTIyMqR53bt31zrP+vLLL8PNzQ1t27bF+PHjsXXrVty9e/fxPw7+f+Rak9psy6PCw8MxZcoUBAQEYOnSpY/9PeXEcCUiakCPHopUKBTQaDQAHr6MwNnZGampqVqfjIwMzJ07t97WK6e/hy8AWFtb4/Tp09i2bRucnZ2xcOFCeHl5obCw8LHfr83jLOuyLVFRUUhPT8eQIUNw8OBBdOnSBTt37nziuuqK4UpE1EQ8//zzyM3NhZGREdq3b6/1sbe3r9JfqVTCyclJOq8IPHypwenTp+u0/uPHj1eZ7ty5MwCgc+fOOHv2LEpKSqT2xMREGBgYSBcuVcfIyAgBAQGIiYlBWloarl69ioMHDz62r6enJ+Lj4+tUfyVjY2Otc7SVOnbsiFmzZiE2NhYjR47Epk2bnmo9NWG4EhE1EQEBAfD19cXw4cMRGxuLq1ev4tixY/jggw+qvbI1LCwM0dHR+Omnn5CRkYGZM2fi9u3bdXru8vbt2/HVV1/h0qVLWLRoEU6cOCFdsBQSEgIzMzNMnDgR58+fx6FDhxAWFobx48dL51sfZ/fu3Vi1ahVSU1ORlZWFLVu2QKPRVBvIkZGROHnyJN59912kpaXh4sWLWL9+Pf76669ab0ebNm0QHx+P3Nxc3L59G/fu3cP06dNx+PBhZGVlITExESdPnpT+x6E+8IImImo29P353AqFAnv37sUHH3yAt956Czdv3oRKpYKfn1+1ARYREYHc3FxMmDABhoaGmDZtGgIDA2FoaKjz+hcvXozvvvsO7777LpydnbFt2zZ06dIFwMN3nO7fvx8zZ85E7969YWFhgVGjRmHFihU1LtPW1hY7duxAVFQUSktL0aFDB2zbtq3KRUqVOnbsiNjYWPzzn/9Enz59YG5uDh8fH4wbN67W27F8+XKEh4fjiy++QMuWLXHp0iXcunULEyZMQF5eHuzt7TFy5EgsXry49j+OjhSCbxp+IrVaDaVSiaKiItjY2DzVsvjgfqKnV1paiszMTLi7u9f5lWDNlUajQefOnfHGG2/gww8/bOxy9FJNf79qmwccuRIR6bGsrCzExsZi4MCBuH//PtasWYPMzEy8+eabjV3aM43nXImI9JiBgQE2b96M3r17o1+/fjh37hwOHDhQr+cT6ck4ciUi0mOurq5ITExs7DLoERy5EhERyYzhSkR6i9djUn2Q4+8Vw5WI9E7lbSZlZWWNXAk1R5WPZ3yaB/vznCsR6R0jIyNYWFjg5s2bMDY2hoEBxwn09IQQuHv3LvLz82Fra1une4UrMVyJSO8oFAo4OzsjMzMTWVlZjV0ONTOPvlGnLhiuRKSXTExM0KFDBx4aJlkZGxs/1Yi1EsOViPSWgYEBn9BETVKjnqiIjo5G7969YW1tDUdHRwwfPlzrvYDAw8dQhYaGSu83HDVqFPLy8rT6ZGdnY8iQIbCwsICjoyPmzp2LiooKrT6HDx/G888/D1NTU7Rv3x6bN2+u780jIqJnVKOG65EjRxAaGorjx48jLi4O5eXlGDx4sNYrjWbNmoWff/4Z27dvx5EjR3Djxg2MHDlSan/w4AGGDBmCsrIyHDt2DF9//TU2b96MhQsXSn0yMzMxZMgQvPjii0hNTcV7772HKVOmYP/+/Q26vURE9GxoUg/uv3nzJhwdHXHkyBH4+fmhqKgIDg4O+Pbbb/H6668DAC5evIjOnTsjKSkJffv2xS+//IJXX30VN27ckN4asWHDBkRERODmzZswMTFBREQE9uzZg/Pnz0vrGjt2LAoLC7Fv374n1sUH9xMREVD7PGhS168XFRUBAOzs7AAAKSkpKC8vR0BAgNTHw8MDrVu3RlJSEgAgKSkJ3bt313odU2BgINRqNdLT06U+f19GZZ/KZTzq/v37UKvVWh8iIqLaajLhqtFo8N5776Ffv37o1q0bACA3NxcmJiawtbXV6uvk5ITc3Fypz6PvOaycflIftVqNe/fuVaklOjoaSqVS+ri6usqyjURE9GxoMuEaGhqK8+fP47vvvmvsUhAZGYmioiLpc+3atcYuiYiI9EiTuBVn+vTp2L17NxISEtCqVStpvkqlQllZGQoLC7VGr3l5edINviqVCidOnNBaXuXVxH/v8+gVxnl5ebCxsYG5uXmVekxNTWFqairLthER0bOnUUeuQghMnz4dO3fuxMGDB+Hu7q7V7u3tDWNjY8THx0vzMjIykJ2dDV9fXwCAr68vzp07h/z8fKlPXFwcbGxs0KVLF6nP35dR2adyGURERHJq1JFraGgovv32W/z000+wtraWzpEqlUqYm5tDqVRi8uTJCA8Ph52dHWxsbBAWFgZfX1/07dsXADB48GB06dIF48ePR0xMDHJzczF//nyEhoZKo8+3334ba9aswfvvv49//OMfOHjwIH744Qfs2VP9lbtERER11agj1/Xr16OoqAiDBg2Cs7Oz9Pn++++lPp999hleffVVjBo1Cn5+flCpVNixY4fUbmhoiN27d8PQ0BC+vr74n//5H0yYMAFLliyR+ri7u2PPnj2Ii4uDl5cXli9fjo0bNyIwMLBBt5eIiJ4NTeo+16aK97kSERGgp/e5EhERNQcMVyIiIpkxXImIiGTGcCUiIpIZw5WIiEhmDFciIiKZMVyJiIhkxnAlIiKSGcOViIhIZgxXIiIimTFciYiIZMZwJSIikpnO4Xrv3j3cvXtXms7KysLKlSsRGxsra2FERET6SudwHTZsGLZs2QIAKCwshI+PD5YvX45hw4Zh/fr1shdIRESkb3QO19OnT2PAgAEAgB9//BFOTk7IysrCli1bsGrVKtkLJCIi0jc6h+vdu3dhbW0NAIiNjcXIkSNhYGCAvn37IisrS/YCiYiI9I3O4dq+fXvs2rUL165dw/79+zF48GAAQH5+/lO/SJyIiKg50DlcFy5ciDlz5qBNmzbo06cPfH19ATwcxfbs2VP2AomIiPSNka5feP3119G/f3/k5OTAy8tLmu/v748RI0bIWhwREZE+qtN9riqVCtbW1oiLi8O9e/cAAL1794aHh4esxREREekjncP11q1b8Pf3R8eOHfHKK68gJycHADB58mTMnj1b9gKJiIj0jc7hOmvWLBgbGyM7OxsWFhbS/DFjxmDfvn2yFkdERKSPdD7nGhsbi/3796NVq1Za8zt06MBbcYiIiFCHkWtJSYnWiLVSQUEBTE1NZSmKiIhIn+kcrgMGDJAefwgACoUCGo0GMTExePHFF2UtjoiISB/pfFg4JiYG/v7+OHXqFMrKyvD+++8jPT0dBQUFSExMrI8aiYiI9IrOI9du3brh0qVL6N+/P4YNG4aSkhKMHDkSZ86cQbt27eqjRiIiIr2i88gVAJRKJT744AO5ayEiImoWahWuaWlptV6gp6dnnYshIiJqDmoVrj169IBCoYAQAgqFQpovhAAArXkPHjyQuUQiIiL9UqtzrpmZmfjjjz+QmZmJ//73v3B3d8e6deuQmpqK1NRUrFu3Du3atcN///vf+q6XiIioyavVyNXNzU368+jRo7Fq1Sq88sor0jxPT0+4urpiwYIFGD58uOxFEhER6ROdrxY+d+4c3N3dq8x3d3fHb7/9JktRRERE+kzncO3cuTOio6NRVlYmzSsrK0N0dDQ6d+4sa3FERET6SOdbcTZs2IChQ4eiVatW0pXBaWlpUCgU+Pnnn2UvkIiISN/oHK59+vTBH3/8ga1bt+LixYsAHr4R580334SlpaXsBRIREembOj1EwtLSEtOmTZO7FiIiomZB53OuAHDlyhWEhYUhICAAAQEBmDlzJq5cuaLzchISEjB06FC4uLhAoVBg165dWu2TJk2CQqHQ+gQFBWn1KSgoQEhICGxsbGBra4vJkyejuLhYq09aWhoGDBgAMzMzuLq6IiYmRudaiYiIakvncN2/fz+6dOmCEydOwNPTE56enjh+/Di6du2KuLg4nZZVUlICLy8vrF27tto+QUFByMnJkT7btm3Tag8JCUF6ejri4uKwe/duJCQkaI2q1Wo1Bg8eDDc3N6SkpGDZsmWIiorC559/rtuGExER1ZLOh4XnzZuHWbNmYenSpVXmR0RE4OWXX671soKDgxEcHFxjH1NTU6hUqse2XbhwAfv27cPJkyfRq1cvAMDq1avxyiuv4NNPP4WLiwu2bt2KsrIyfPXVVzAxMUHXrl2RmpqKFStW8NA2ERHVC51HrhcuXMDkyZOrzP/HP/5RL/e5Hj58GI6OjujUqRPeeecd3Lp1S2pLSkqCra2tFKwAEBAQAAMDAyQnJ0t9/Pz8YGJiIvUJDAxERkYGbt++/dh13r9/H2q1WutDRERUWzqHq4ODA1JTU6vMT01NhaOjoxw1SYKCgrBlyxbEx8fjk08+wZEjRxAcHCw9vzg3N7fKOo2MjGBnZ4fc3Fypj5OTk1afyunKPo+Kjo6GUqmUPq6urrJuFxERNW86HxaeOnUqpk2bhj/++AMvvPACACAxMRGffPIJwsPDZS1u7Nix0p+7d+8OT09PtGvXDocPH4a/v7+s6/q7yMhIrW1Rq9UMWCIiqjWdw3XBggWwtrbG8uXLERkZCQBwcXFBVFQUZsyYIXuBf9e2bVvY29vj8uXL8Pf3h0qlQn5+vlafiooKFBQUSOdpVSoV8vLytPpUTld3LtfU1BSmpqb1sAVERPQs0PmwsEKhwKxZs3D9+nUUFRWhqKgI169fx8yZM7VePVcfrl+/jlu3bsHZ2RkA4Ovri8LCQqSkpEh9Dh48CI1GAx8fH6lPQkICysvLpT5xcXHo1KkTnnvuuXqtl4iInk11us+1krW1Naytrev8/eLiYum1dcDDV9ulpqYiOzsbxcXFmDt3Lo4fP46rV68iPj4ew4YNQ/v27REYGAjg4XOOg4KCMHXqVJw4cQKJiYmYPn06xo4dCxcXFwDAm2++CRMTE0yePBnp6en4/vvv8e9//1v2Q9hERESVdA7XvLw8jB8/Hi4uLjAyMoKhoaHWRxenTp1Cz5490bNnTwBAeHg4evbsiYULF8LQ0BBpaWl47bXX0LFjR0yePBne3t749ddftQ7Zbt26FR4eHvD398crr7yC/v37a93DqlQqERsbi8zMTHh7e2P27NlYuHAhb8MhIqJ6oxBCCF2+EBwcjOzsbEyfPh3Ozs5VDgUPGzZM1gKbArVaDaVSiaKiItjY2DzVstrM21Nt29WlQ55q2UREVL9qmwc6X9B09OhR/Prrr+jRo8fT1EdERNRs6XxY2NXVFToOdomIiJ4pOofrypUrMW/ePFy9erUeyiEiItJ/Oh8WHjNmDO7evYt27drBwsICxsbGWu0FBQWyFUdERKSPdA7XlStX1kMZREREzYfO4Tpx4sT6qIOIiKjZeKqHSBAREVFVDFciIiKZMVyJiIhkVqtwTUtLg0ajqe9aiIiImoVahWvPnj3x119/AXj42rdbt27Va1FERET6rFbhamtri8zMTADA1atXOYolIiKqQa1uxRk1ahQGDhwoPai/V69e1b4B548//pC1QCIiIn1Tq3D9/PPPMXLkSFy+fBkzZszA1KlTn+o9rkRERM1ZrR8iERQUBABISUnBzJkzGa5ERETV0PkJTZs2bZL+fP36dQBAq1at5KuIiIhIz+l8n6tGo8GSJUugVCrh5uYGNzc32Nra4sMPP+SFTkRERKjDyPWDDz7Al19+iaVLl6Jfv34AHr5APSoqCqWlpfjXv/4le5FERET6ROdw/frrr7Fx40a89tpr0jxPT0+0bNkS7777LsOViIieeTofFi4oKICHh0eV+R4eHnyXKxEREeoQrl5eXlizZk2V+WvWrIGXl5csRREREekznQ8Lx8TEYMiQIThw4AB8fX0BAElJSbh27Rr27t0re4FERET6RueR68CBA3Hp0iWMGDEChYWFKCwsxMiRI5GRkYEBAwbUR41ERER6ReeRKwC4uLjwwiUiIqJq8H2uREREMmO4EhERyYzhSkREJDOdwlUIgezsbJSWltZXPURERHpP53Bt3749rl27Vl/1EBER6T2dwtXAwAAdOnTArVu36qseIiIivafzOdelS5di7ty5OH/+fH3UQ0REpPd0vs91woQJuHv3Lry8vGBiYgJzc3Otdj5fmIiInnU6h+vKlSvroQwiIqLmQ+dwnThxYn3UQURE1GzU6T7XK1euYP78+Rg3bhzy8/MBAL/88gvS09NlLY6IiEgf6RyuR44cQffu3ZGcnIwdO3aguLgYAHD27FksWrRI9gKJiIj0jc7hOm/ePHz00UeIi4uDiYmJNP+ll17C8ePHZS2OiIhIH+kcrufOncOIESOqzHd0dMRff/2l07ISEhIwdOhQuLi4QKFQYNeuXVrtQggsXLgQzs7OMDc3R0BAAH7//XetPgUFBQgJCYGNjQ1sbW0xefJkaTRdKS0tDQMGDICZmRlcXV0RExOjU51ERES60DlcbW1tkZOTU2X+mTNn0LJlS52WVVJSAi8vL6xdu/ax7TExMVi1ahU2bNiA5ORkWFpaIjAwUOvxiyEhIUhPT0dcXBx2796NhIQETJs2TWpXq9UYPHgw3NzckJKSgmXLliEqKgqff/65TrUSERHVls5XC48dOxYRERHYvn07FAoFNBoNEhMTMWfOHEyYMEGnZQUHByM4OPixbUIIrFy5EvPnz8ewYcMAAFu2bIGTkxN27dqFsWPH4sKFC9i3bx9OnjyJXr16AQBWr16NV155BZ9++ilcXFywdetWlJWV4auvvoKJiQm6du2K1NRUrFixQiuEiYiI5KLzyPXjjz+Gh4cHXF1dUVxcjC5dusDPzw8vvPAC5s+fL1thmZmZyM3NRUBAgDRPqVTCx8cHSUlJAICkpCTY2tpKwQoAAQEBMDAwQHJystTHz89P6/xwYGAgMjIycPv27ceu+/79+1Cr1VofIiKi2tI5XE1MTPDFF1/gypUr2L17N7755htcvHgR//nPf2BoaChbYbm5uQAAJycnrflOTk5SW25uLhwdHbXajYyMYGdnp9Xnccv4+zoeFR0dDaVSKX1cXV2ffoOIiOiZofNh4UqtW7eWQkehUMhWUFMQGRmJ8PBwaVqtVjNgiYio1ur0EIkvv/wS3bp1g5mZGczMzNCtWzds3LhR1sJUKhUAIC8vT2t+Xl6e1KZSqaSHWFSqqKhAQUGBVp/HLePv63iUqakpbGxstD5ERES1pXO4Lly4EDNnzsTQoUOxfft2bN++HUOHDsWsWbOwcOFC2Qpzd3eHSqVCfHy8NE+tViM5ORm+vr4AAF9fXxQWFiIlJUXqc/DgQWg0Gvj4+Eh9EhISUF5eLvWJi4tDp06d8Nxzz8lWLxERUSWdDwuvX78eX3zxBcaNGyfNe+211+Dp6YmwsDAsWbKk1ssqLi7G5cuXpenMzEykpqbCzs4OrVu3xnvvvYePPvoIHTp0gLu7OxYsWAAXFxcMHz4cANC5c2cEBQVh6tSp2LBhA8rLyzF9+nSMHTsWLi4uAIA333wTixcvxuTJkxEREYHz58/j3//+Nz777DNdN52IiKhWdA7X8vJyratzK3l7e6OiokKnZZ06dQovvviiNF15nnPixInYvHkz3n//fZSUlGDatGkoLCxE//79sW/fPpiZmUnf2bp1K6ZPnw5/f38YGBhg1KhRWLVqldSuVCoRGxuL0NBQeHt7w97eHgsXLuRtOEREVG8UQgihyxfCwsJgbGyMFStWaM2fM2cO7t27V+0DIfSZWq2GUqlEUVHRU59/bTNvT7VtV5cOeaplExFR/aptHtRq5Pr3K2cVCgU2btyI2NhY9O3bFwCQnJyM7OxsnR8iQURE1BzVKlzPnDmjNe3t7Q3g4avnAMDe3h729vZ85RwRERFqGa6HDh2q7zqIiIiajTrd50pERETV0/lq4dLSUqxevRqHDh1Cfn4+NBqNVvvp06dlK46IiEgf6RyukydPRmxsLF5//XX06dOn2T36kIiI6GnpHK67d+/G3r170a9fv/qoh4iISO/pfM61ZcuWsLa2ro9aiIiImgWdw3X58uWIiIhAVlZWfdRDRESk93Q+LNyrVy+Ulpaibdu2sLCwgLGxsVZ7QUGBbMURERHpI53Dddy4cfjzzz/x8ccfw8nJiRc0ERERPULncD127BiSkpLg5eVVH/UQERHpPZ3PuXp4eODevXv1UQsREVGzoHO4Ll26FLNnz8bhw4dx69YtqNVqrQ8REdGzTufDwkFBQQAAf39/rflCCCgUCjx48ECeyoiIiPSUzuHKh/gTERHVTOdwHThwYH3UQURE1GzoHK4JCQk1tvv5+dW5GCIiouZA53AdNGhQlXl/v9eV51yJiOhZp/PVwrdv39b65OfnY9++fejduzdiY2Pro0YiIiK9ovPIValUVpn38ssvw8TEBOHh4UhJSZGlMCIiIn2l88i1Ok5OTsjIyJBrcURERHpL55FrWlqa1rQQAjk5OVi6dCl69OghV11ERER6S+dw7dGjBxQKBYQQWvP79u2Lr776SrbCiIiI9JXO4ZqZmak1bWBgAAcHB5iZmclWFBERkT7TOVzd3Nzqow4iIqJmQ+dwBYD4+HjEx8cjPz8fGo1Gq42HhomI6Fmnc7guXrwYS5YsQa9eveDs7MyXpRMRET1C53DdsGEDNm/ejPHjx9dHPURERHpP5/tcy8rK8MILL9RHLURERM2CzuE6ZcoUfPvtt/VRCxERUbOg82Hh0tJSfP755zhw4AA8PT1hbGys1b5ixQrZiiMiItJHdXpCU+WTmM6fP6/VxoubiIiI6hCuhw4dqo86iIiImg3ZHtxPREREDzFciYiIZMZwJSIiklmTDteoqCgoFAqtj4eHh9ReWlqK0NBQtGjRAlZWVhg1ahTy8vK0lpGdnY0hQ4bAwsICjo6OmDt3LioqKhp6U4iI6BlSp2cLN6SuXbviwIED0rSR0f+XPGvWLOzZswfbt2+HUqnE9OnTMXLkSCQmJgIAHjx4gCFDhkClUuHYsWPIycnBhAkTYGxsjI8//rjBt4WIiJ4NTT5cjYyMoFKpqswvKirCl19+iW+//RYvvfQSAGDTpk3o3Lkzjh8/jr59+yI2Nha//fYbDhw4ACcnJ/To0QMffvghIiIiEBUVBRMTk4beHCIiegY06cPCAPD777/DxcUFbdu2RUhICLKzswEAKSkpKC8vR0BAgNTXw8MDrVu3RlJSEgAgKSkJ3bt3h5OTk9QnMDAQarUa6enp1a7z/v37UKvVWh8iIqLaatLh6uPjg82bN2Pfvn1Yv349MjMzMWDAANy5cwe5ubkwMTGBra2t1necnJyQm5sLAMjNzdUK1sr2yrbqREdHQ6lUSh9XV1d5N4yIiJq1Jn1YODg4WPqzp6cnfHx84Obmhh9++AHm5ub1tt7IyEiEh4dL02q1mgFLRES11qRHro+ytbVFx44dcfnyZahUKpSVlaGwsFCrT15ennSOVqVSVbl6uHL6cedxK5mamsLGxkbrQ0REVFt6Fa7FxcW4cuUKnJ2d4e3tDWNjY8THx0vtGRkZyM7Ohq+vLwDA19cX586dQ35+vtQnLi4ONjY26NKlS4PXT0REz4YmfVh4zpw5GDp0KNzc3HDjxg0sWrQIhoaGGDduHJRKJSZPnozw8HDY2dnBxsYGYWFh8PX1Rd++fQEAgwcPRpcuXTB+/HjExMQgNzcX8+fPR2hoKExNTRt564iIqLlq0uF6/fp1jBs3Drdu3YKDgwP69++P48ePw8HBAQDw2WefwcDAAKNGjcL9+/cRGBiIdevWSd83NDTE7t278c4778DX1xeWlpaYOHEilixZ0libREREzwCFEEI0dhFNnVqthlKpRFFR0VOff20zb0+1bVeXDnmqZRMRUf2qbR7o1TlXIiIifcBwJSIikhnDlYiISGYMVyIiIpkxXImIiGTGcCUiIpIZw5WIiEhmDFciIiKZMVyJiIhkxnAlIiKSGcOViIhIZgxXIiIimTFciYiIZMZwJSIikhnDlYiISGYMVyIiIpkxXImIiGRm1NgF0P9rM29PtW1Xlw5pwEqIiOhpcORKREQkM4YrERGRzBiuREREMmO4EhERyYzhSkREJDOGKxERkcwYrkRERDJjuBIREcmM4UpERCQzhisREZHMGK5EREQyY7gSERHJjOFKREQkM4YrERGRzBiuREREMuP7XPUE3/VKRKQ/OHIlIiKSGcOViIhIZgxXIiIimT1T51zXrl2LZcuWITc3F15eXli9ejX69OnT2GU9NZ6PJSJqWp6Zkev333+P8PBwLFq0CKdPn4aXlxcCAwORn5/f2KUREVEzoxBCiMYuoiH4+Pigd+/eWLNmDQBAo9HA1dUVYWFhmDdvXo3fVavVUCqVKCoqgo2NzVPVUdMosynhiJeIqKra5sEzcVi4rKwMKSkpiIyMlOYZGBggICAASUlJVfrfv38f9+/fl6aLiooAPPxRn5bm/t2nXkZDaD1re7Vt5xcHVtvWbdH+Oq2vpmUSETUVlTnwpHHpMxGuf/31Fx48eAAnJyet+U5OTrh48WKV/tHR0Vi8eHGV+a6urvVWoz5RrtSPZRIR1Zc7d+5AqVRW2/5MhKuuIiMjER4eLk1rNBoUFBSgRYsWUCgUdV6uWq2Gq6srrl279tSHl5sKbpN+4DbpB25T0yeEwJ07d+Di4lJjv2ciXO3t7WFoaIi8vDyt+Xl5eVCpVFX6m5qawtTUVGuera2tbPXY2Ng0i79kf8dt0g/cJv3AbWraahqxVnomrhY2MTGBt7c34uPjpXkajQbx8fHw9fVtxMqIiKg5eiZGrgAQHh6OiRMnolevXujTpw9WrlyJkpISvPXWW41dGhERNTPPTLiOGTMGN2/exMKFC5Gbm4sePXpg3759VS5yqk+mpqZYtGhRlUPO+ozbpB+4TfqB29R8PDP3uRIRETWUZ+KcKxERUUNiuBIREcmM4UpERCQzhisREZHMGK4NaO3atWjTpg3MzMzg4+ODEydONHZJtRIdHY3evXvD2toajo6OGD58ODIyMrT6DBo0CAqFQuvz9ttvN1LFTxYVFVWlXg8PD6m9tLQUoaGhaNGiBaysrDBq1KgqDyFpitq0aVNluxQKBUJDQwHox35KSEjA0KFD4eLiAoVCgV27dmm1CyGwcOFCODs7w9zcHAEBAfj999+1+hQUFCAkJAQ2NjawtbXF5MmTUVxc3IBboa2mbSovL0dERAS6d+8OS0tLuLi4YMKECbhx44bWMh63b5cuXdrAW/L/nrSfJk2aVKXeoKAgrT5NbT/JieHaQPT5lXdHjhxBaGgojh8/jri4OJSXl2Pw4MEoKSnR6jd16lTk5ORIn5iYmEaquHa6du2qVe/Ro0eltlmzZuHnn3/G9u3bceTIEdy4cQMjR45sxGpr5+TJk1rbFBcXBwAYPXq01Kep76eSkhJ4eXlh7dq1j22PiYnBqlWrsGHDBiQnJ8PS0hKBgYEoLS2V+oSEhCA9PR1xcXHYvXs3EhISMG3atIbahCpq2qa7d+/i9OnTWLBgAU6fPo0dO3YgIyMDr732WpW+S5Ys0dp3YWFhDVH+Yz1pPwFAUFCQVr3btm3Tam9q+0lWghpEnz59RGhoqDT94MED4eLiIqKjoxuxqrrJz88XAMSRI0ekeQMHDhQzZ85svKJ0tGjRIuHl5fXYtsLCQmFsbCy2b98uzbtw4YIAIJKSkhqoQnnMnDlTtGvXTmg0GiGE/u0nAGLnzp3StEajESqVSixbtkyaV1hYKExNTcW2bduEEEL89ttvAoA4efKk1OeXX34RCoVC/Pnnnw1We3Ue3abHOXHihAAgsrKypHlubm7is88+q9/i6uhx2zRx4kQxbNiwar/T1PfT0+LItQFUvvIuICBAmlfTK++auspX8NnZ2WnN37p1K+zt7dGtWzdERkbi7t2m/Xq933//HS4uLmjbti1CQkKQnZ0NAEhJSUF5ebnW/vLw8EDr1q31an+VlZXhm2++wT/+8Q+tF07o2376u8zMTOTm5mrtG6VSCR8fH2nfJCUlwdbWFr169ZL6BAQEwMDAAMnJyQ1ec10UFRVBoVBUeab50qVL0aJFC/Ts2RPLli1DRUVF4xRYS4cPH4ajoyM6deqEd955B7du3ZLamsN+qskz84SmxqTrK++aMo1Gg/feew/9+vVDt27dpPlvvvkm3Nzc4OLigrS0NERERCAjIwM7duxoxGqr5+Pjg82bN6NTp07IycnB4sWLMWDAAJw/fx65ubkwMTGp8h82Jycn5ObmNk7BdbBr1y4UFhZi0qRJ0jx920+Pqvz9H/dvqbItNzcXjo6OWu1GRkaws7PTi/1XWlqKiIgIjBs3TutB9zNmzMDzzz8POzs7HDt2DJGRkcjJycGKFSsasdrqBQUFYeTIkXB3d8eVK1fwz3/+E8HBwUhKSoKhoaHe76cnYbiSTkJDQ3H+/Hmt85MAtM6TdO/eHc7OzvD398eVK1fQrl27hi7ziYKDg6U/e3p6wsfHB25ubvjhhx9gbm7eiJXJ58svv0RwcLDWq7H0bT89a8rLy/HGG29ACIH169drtf39NZienp4wMTHB//7v/yI6OrpJPlpw7Nix0p+7d+8OT09PtGvXDocPH4a/v38jVtYweFi4Aej6yrumavr06di9ezcOHTqEVq1a1djXx8cHAHD58uWGKO2p2draomPHjrh8+TJUKhXKyspQWFio1Uef9ldWVhYOHDiAKVOm1NhP3/ZT5e9f078llUpV5ULBiooKFBQUNOn9VxmsWVlZiIuLe+Lr2Xx8fFBRUYGrV682TIFPqW3btrC3t5f+runrfqothmsD0PdX3gkhMH36dOzcuRMHDx6Eu7v7E7+TmpoKAHB2dq7n6uRRXFyMK1euwNnZGd7e3jA2NtbaXxkZGcjOztaL/QUAmzZtgqOjI4YMGVJjP33bT+7u7lCpVFr7Rq1WIzk5Wdo3vr6+KCwsREpKitTn4MGD0Gg00v9MNDWVwfr777/jwIEDaNGixRO/k5qaCgMDgyqHVpuq69ev49atW9LfNX3cTzpp7CuqnhXfffedMDU1FZs3bxa//fabmDZtmrC1tRW5ubmNXdoTvfPOO0KpVIrDhw+LnJwc6XP37l0hhBCXL18WS5YsEadOnRKZmZnip59+Em3bthV+fn6NXHn1Zs+eLQ4fPiwyMzNFYmKiCAgIEPb29iI/P18IIcTbb78tWrduLQ4ePChOnTolfH19ha+vbyNXXTsPHjwQrVu3FhEREVrz9WU/3blzR5w5c0acOXNGABArVqwQZ86cka6cXbp0qbC1tRU//fSTSEtLE8OGDRPu7u7i3r170jKCgoJEz549RXJysjh69Kjo0KGDGDduXGNtUo3bVFZWJl577TXRqlUrkZqaqvVv7P79+0IIIY4dOyY+++wzkZqaKq5cuSK++eYb4eDgICZMmNAkt+nOnTtizpw5IikpSWRmZooDBw6I559/XnTo0EGUlpZKy2hq+0lODNcGtHr1atG6dWthYmIi+vTpI44fP97YJdUKgMd+Nm3aJIQQIjs7W/j5+Qk7Ozthamoq2rdvL+bOnSuKiooat/AajBkzRjg7OwsTExPRsmVLMWbMGHH58mWp/d69e+Ldd98Vzz33nLCwsBAjRowQOTk5jVhx7e3fv18AEBkZGVrz9WU/HTp06LF/3yZOnCiEeHg7zoIFC4STk5MwNTUV/v7+Vbb11q1bYty4ccLKykrY2NiIt956S9y5c6cRtuahmrYpMzOz2n9jhw4dEkIIkZKSInx8fIRSqRRmZmaic+fO4uOPP9YKqqa0TXfv3hWDBw8WDg4OwtjYWLi5uYmpU6dWGUw0tf0kJ75yjoiISGY850pERCQzhisREZHMGK5EREQyY7gSERHJjOFKREQkM4YrERGRzBiuREREMmO4EpFk8+bNVd4G9CSTJk3C8OHDa+zTpk0brFy5ss51EekbhitRE3Tz5k2YmJigpKQE5eXlsLS0lN43W5/GjBmDS5cu1ft6iJo7vnKOqAlKSkqCl5cXLC0tkZycDDs7O7Ru3bre12tubq43r9wrKyuDiYlJY5dB9FgcuRI1QceOHUO/fv0AAEePHpX+XJPKw7OffvopnJ2d0aJFC4SGhqK8vFzqc//+fcyZMwctW7aEpaUlfHx8cPjwYan9cYeFP/roIzg6OsLa2hpTpkzBvHnz0KNHjyrrr2m9AHDnzh2MGzcOlpaWaNmyJdauXavVnp2djWHDhsHKygo2NjZ44403tF4tFxUVhR49emDjxo1wd3eHmZkZAODHH39E9+7dYW5ujhYtWiAgIAAlJSVP/L2I6lVjP9yYiB7KysoSSqVSKJVKYWxsLMzMzIRSqRQmJibC1NRUKJVK8c4771T7/YkTJwobGxvx9ttviwsXLoiff/5ZWFhYiM8//1zqM2XKFPHCCy+IhIQEcfnyZbFs2TJhamoqLl26JIQQYtOmTUKpVEr9v/nmG2FmZia++uorkZGRIRYvXixsbGyEl5eXTut1c3MT1tbWIjo6WmRkZIhVq1YJQ0NDERsbK4R4+CafHj16iP79+4tTp06J48ePC29vbzFw4EBpGYsWLRKWlpYiKChInD59Wpw9e1bcuHFDGBkZiRUrVojMzEyRlpYm1q5d22we/k76i+FK1ESUl5eLzMxMcfbsWWFsbCzOnj0rLl++LKysrMSRI0dEZmamuHnzZrXfnzhxonBzcxMVFRXSvNGjR4sxY8YIIR6Gt6Ghofjzzz+1vufv7y8iIyOFEFXD1cfHR4SGhmr179evX5VwrWm9QjwM16CgIK3ljBkzRgQHBwshhIiNjRWGhoYiOztbak9PTxcAxIkTJ4QQD8PV2NhYei2gEA/fFgNAXL16tdrfhagx8LAwURNhZGSENm3a4OLFi+jduzc8PT2Rm5sLJycn+Pn5oU2bNrC3t69xGV27doWhoaE07ezsjPz8fADAuXPn8ODBA3Ts2BFWVlbS58iRI7hy5cpjl5eRkYE+ffpozXt0+knrrfToi+Z9fX1x4cIFAMCFCxfg6uoKV1dXqb1Lly6wtbWV+gCAm5sbHBwcpGkvLy/4+/uje/fuGD16NL744gvcvn378T8OUQPiBU1ETUTXrl2RlZWF8vJyaDQaWFlZoaKiAhUVFbCysoKbmxvS09NrXIaxsbHWtEKhgEajAQAUFxfD0NAQKSkpWkEIAFZWVk9Ve03rlZOlpaXWtKGhIeLi4nDs2DHExsZi9erV+OCDD5CcnAx3d3fZ109UWxy5EjURe/fuRWpqKlQqFb755hukpqaiW7duWLlyJVJTU7F3796nWn7Pnj3x4MED5Ofno3379loflUr12O906tQJJ0+e1Jr36HRtHT9+vMp0586dAQCdO3fGtWvXcO3aNan9t99+Q2FhIbp06VLjchUKBfr164fFixfjzJkzMDExwc6dO+tUI5FcOHIlaiLc3NyQm5uLvLw8DBs2DAqFAunp6Rg1ahScnZ2fevkdO3ZESEgIJkyYgOXLl6Nnz564efMm4uPj4enpiSFDhlT5TlhYGKZOnYpevXrhhRdewPfff4+0tDS0bdtW5/UnJiYiJiYGw4cPR1xcHLZv3449e/YAAAICAtC9e3eEhIRg5cqVqKiowLvvvouBAweiV69e1S4zOTkZ8fHxGDx4MBwdHZGcnIybN29KoU3UWBiuRE3I4cOH0bt3b5iZmeHXX39Fq1atZAnWSps2bcJHH32E2bNn488//4S9vT369u2LV1999bH9Q0JC8Mcff2DOnDkoLS3FG2+8gUmTJuHEiRM6r3v27Nk4deoUFi9eDBsbG6xYsQKBgYEAHo4+f/rpJ4SFhcHPzw8GBgYICgrC6tWra1ymjY0NEhISsHLlSqjVari5uWH58uUIDg7WuT4iOSmEEKKxiyAi/fHyyy9DpVLhP//5T2OXQtRkceRKRNW6e/cuNmzYgMDAQBgaGmLbtm04cOAA4uLiGrs0oiaNI1ciqta9e/cwdOhQnDlzBqWlpejUqRPmz5+PkSNHNnZpRE0aw5WIiEhmvBWHiIhIZgxXIiIimTFciYiIZMZwJSIikhnDlYiISGYMVyIiIpkxXImIiGTGcCUiIpIZw5WIiEhm/wc3gVBg9JSq1AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 统计节点邻居数量的分布情况\n",
    "neighbors_cnts = [loc[1] - loc[0] for node,loc in vertex_edge_loc.items()]\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "# x 轴用对数刻度\n",
    "plt.hist(neighbors_cnts, bins=50, label='neighbors cnts')\n",
    "plt.xlabel('# neighbors')\n",
    "plt.ylabel('number of nodes')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理图数据时，我们有两种常用方案，**全图处理**和**子图采样**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 全图处理方案**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**全图处理适用于处理规模不太大的图数据**，这样一张完整的图信息（包含图连接关系，以及节点、边上的特征）能够**一次性加载到内存中进行计算**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在**图中的节点、以及图中的边都是采用节点名称来表示的**，这**不便于在之后的计算中通过索引快速访问所需要的节点、以及连接节点的边，节点的邻居**，因此，我们还需要进一步对图的表示做一些调整：\n",
    "* 我们为每个节点 `node` 分配一个索引 `node_idx` ，从 `0, 1, 2, ..` 开始编号\n",
    "* 将 `edges` 中保存的边的连接从 `node1 <- node2` 变为 `node1_idx <- node2_idx`\n",
    "* 用一个张量 `neighbors_idx` 存储每个节点的邻居索引\n",
    "  * 第 `i` 行存放了节点索引为 `i` 的邻居节点的索引\n",
    "  * 由于每个节点的邻居数量不同，我们可以选取一个 `num_neighbors` 参数\n",
    "    * 小于 `num_neighbors` 就用 0 填充，邻居数超过 `num_neighbors` 的随机采样 `num_neighbors` 个邻居截断\n",
    "    * 与文本任务类似，我们可以用 `valid_lens` 来存储每一行的有效邻居个数\n",
    "  * 张量 `neighbors_idx` 的形状应该是 `(num_nodes, num_neighbors)` \n",
    "* 同理，可以用一个张量 `connected_edges_idx` 存储每个节点的相连接的边索引\n",
    "  * 因为要拼装成张量，同样需要填充和截断，将相连边的数量固定到 `num_neighbors`\n",
    "  * 这可以帮助我们快速访问到与节点相连接的边上的特征\n",
    "* 通过一个**参数 `is_undirectional` 来控制是有向图还是无向图**\n",
    "  * 如果设置 `is_undirectional = True` 为无向图，则我们需要**颠倒 `edegs` 中的连接关系，复制一份**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_graph(vertex, edges, num_neighbors : int=25, is_undirectional : bool=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vertex : list\n",
    "        节点列表\n",
    "    edges : list\n",
    "        边列表，每个元素为 (node1, node2, edge_feat)\n",
    "    num_neighbors : int\n",
    "        每个节点的采样或填充的邻居数量\n",
    "    is_undirectional : bool\n",
    "        是否为无向图\n",
    "    \"\"\"\n",
    "    # 无向图，边是双向的，所以需要将边复制一份，交换两个节点的位置\n",
    "    if is_undirectional:\n",
    "        edges = edges + [(edge[1], edge[0], edge[2]) for edge in edges]\n",
    "    \n",
    "    # 为每个节点设置索引\n",
    "    vertex_idx = {}\n",
    "    for i,node in enumerate(vertex):\n",
    "        vertex_idx[node] = i\n",
    "\n",
    "    # 将边的连接关系转换为其索引的表示\n",
    "    edges_idx = [(vertex_idx[edge[0]], vertex_idx[edge[1]], edge[2]) for edge in edges]\n",
    "    # 找到每个节点邻居在 edges_idx 中的起始位置\n",
    "    edges_idx, vertex_edge_loc = ch8.compute_vertex_edge_loc(vertex=vertex_idx.values(), edges=edges_idx)\n",
    "\n",
    "    # 为每个节点构造邻居节点的索引，相连接的边的索引\n",
    "    # 邻居数小于 num_neighbors 的节点用 -1 填充\n",
    "    # 邻居数大于 num_neighbors 的节点通过随机采样来截断\n",
    "    # valid_len 保存每个节点的有效邻居数\n",
    "    neighbors_idx = [[-1] * num_neighbors for _ in range(len(vertex))]\n",
    "    connected_edges_idx = [[-1] * num_neighbors for _ in range(len(vertex))]\n",
    "    valid_lens = [0] * len(vertex)\n",
    "\n",
    "    for i, (node_idx, (start, end)) in enumerate(vertex_edge_loc.items()):\n",
    "        # 获取节点的邻居节点索引\n",
    "        node_neighbors_idx = [edges_idx[idx][1] for idx in range(start, end)]\n",
    "        valid_lens[i] = min(len(node_neighbors_idx), num_neighbors) # 记录节点的有效邻居数\n",
    "\n",
    "        if end - start > num_neighbors:\n",
    "            # 邻居数大于 num_neighbors 的节点通过随机采样来截断\n",
    "            connected_edges_idx[i] = np.random.choice(list(range(start,end)), num_neighbors, replace=False)\n",
    "            neighbors_idx[i] = [edges_idx[idx][1] for idx in connected_edges_idx[i]]\n",
    "        else:\n",
    "            # 邻居数小于 num_neighbors 的节点用 0 填充\n",
    "            neighbors_idx[i][:end-start] = node_neighbors_idx[:]\n",
    "            connected_edges_idx[i][:end-start] = list(range(start, end))\n",
    "    \n",
    "    return vertex_idx, edges_idx, neighbors_idx, connected_edges_idx, valid_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_idx, edges_idx, neighbors_idx, connected_edges_idx, valid_lens \\\n",
    "    = ch8.build_global_graph(vertex, edges, num_neighbors=25, is_undirectional=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，给定节点索引，我们就嫩通过 `tf.gather` 快速获取它们的**邻居节点索引，相连的边的索引，以及有效邻居个数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邻居节点索引： tf.Tensor(\n",
      "[[   8  435  544   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1\n",
      "    -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1]\n",
      " [  -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1\n",
      "    -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1]\n",
      " [ 265  758 1611   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1\n",
      "    -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1]], shape=(3, 25), dtype=int32)\n",
      "相连接的边的索引： tf.Tensor(\n",
      "[[  0   1   2  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "   -1  -1  -1  -1  -1  -1  -1]\n",
      " [ -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "   -1  -1  -1  -1  -1  -1  -1]\n",
      " [271 272 273  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "   -1  -1  -1  -1  -1  -1  -1]], shape=(3, 25), dtype=int32)\n",
      "有效邻居数： tf.Tensor([3 0 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "nodes_idx = [0, 10, 100]\n",
    "print(\"邻居节点索引：\", tf.gather(neighbors_idx, nodes_idx))\n",
    "print(\"相连接的边的索引：\", tf.gather(connected_edges_idx, nodes_idx))\n",
    "print(\"有效邻居数：\", tf.gather(valid_lens, nodes_idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在构造 **GNN 层中进行消息传递时，需要收集邻居节点的特征表达**，这也会变得非常容易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 25, 1433])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 收集来自邻居节点的特征\n",
    "tf.gather(vertex_feat, tf.gather(neighbors_idx, nodes_idx)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在使用 `tf.gather` 访问节点邻居特征时，**如果对应索引为 `-1`（即我们进行了填充），则对应位置处 Tensorflow 会使用零向量填充**，可以参照下面的这个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[0.12244976, 0.14168298, 0.3059963 , 0.08443999, 0.1580081 ],\n",
       "       [0.87276995, 0.799152  , 0.36884093, 0.91919506, 0.24743366],\n",
       "       [0.534055  , 0.18407106, 0.41021943, 0.40592825, 0.07577908]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((3,5))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[0.12244976, 0.14168298, 0.3059963 , 0.08443999, 0.1580081 ],\n",
       "        [0.87276995, 0.799152  , 0.36884093, 0.91919506, 0.24743366],\n",
       "        [0.534055  , 0.18407106, 0.41021943, 0.40592825, 0.07577908]],\n",
       "\n",
       "       [[0.534055  , 0.18407106, 0.41021943, 0.40592825, 0.07577908],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 索引为 -1 处的变量会自动用零向量填充\n",
    "tf.gather(X, [[0,1,2],[2,-1,-1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时**一个 GNN 层接收下面几个输入**，注意，**我们在所有图信息的数据上，都额外增加了第一个维度，即批量维度 `batch_size`**，在 GNN 批量处理图数据时，`batch_size = num_graph`，对于**全图处理方案，整个图数据就是一张图，因此这里 `batch_size = num_graph = 1`**\n",
    "* 关于**图的特征部分**：\n",
    "  * `vertex_feat`：节点特征张量，形状 `(1, num_nodes, num_feats)`\n",
    "  * `edges_feat`：边特征张量，形状 `(1, num_edges, num_feats)`\n",
    "  * `graph_feat`：全局图特征张量，形状 `(1, num_feats)`\n",
    "    * 如果**没有全图特征张量**，但在 GNN 中需要使用全局特征张量时，可以用图中节点特征向量的均值做初始化\n",
    "* 关于**图的结构部分**：\n",
    "  * `edges_idx`：边的连接关系，对应两端的节点索引，形状 `(1, num_edges, 2)`\n",
    "  * `neighbors_idx`：邻居节点索引张量，形状 `(1, num_nodes, num_neighbors)`\n",
    "  * `connected_edges_idx`：相连的边索引张量，形状 `(1, num_nodes, num_neighbors)`\n",
    "  * `valid_lens`：有效邻居个数，形状 `(1, num_nodes)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将以上的功能包装，创建 `Cora` 节点类型任务的数据集\n",
    "* 我们可以将所有节点划分为训练集、验证集两部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_nodetask_data(path : str, num_neighbors : int=25, is_undirectional : bool=True, test_size : float=0.4):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # 加载 cora 数据集\n",
    "    vertex, vertex_feat, vertex_class, edges, class_map = ch8.load_cora(path=path)\n",
    "    # 构造全图信息\n",
    "    vertex_idx, edges_idx, neighbors_idx, connected_edges_idx, valid_lens \\\n",
    "        = ch8.build_global_graph(vertex, edges, num_neighbors=num_neighbors, is_undirectional=is_undirectional)\n",
    "\n",
    "    # 从 edges_idx 中获取边的特征\n",
    "    edges_feat = [edge[2] for edge in edges_idx]\n",
    "    edges_idx = [(edge[0], edge[1]) for edge in edges_idx]\n",
    "\n",
    "    # 构造图，并将所有信息转换为张量\n",
    "    graph = {\n",
    "        # 图上的特征\n",
    "        'vertex_feat': tf.constant(vertex_feat, dtype=tf.int32)[None,:],\n",
    "        'edges_feat': None, # cora 数据集没有边的特征\n",
    "        'graph_feat': None, # cora 数据集没有图的特征\n",
    "        # 图的连接信息\n",
    "        'vertex_idx': vertex_idx, # 节点名称到索引的映射\n",
    "        'edges_idx': tf.constant(edges_idx, dtype=tf.int32)[None,:],\n",
    "        'neighbors_idx': tf.constant(neighbors_idx, dtype=tf.int32)[None,:],\n",
    "        'connected_edges_idx': tf.constant(connected_edges_idx, dtype=tf.int32)[None,:],\n",
    "        'valid_lens': tf.constant(valid_lens, dtype=tf.int32)[None,:],\n",
    "    }\n",
    "    # 节点的标签\n",
    "    node_labels = tf.constant(vertex_class, dtype=tf.int32)[None,:] # 转换为张量，形状 (1, num_nodes)\n",
    "\n",
    "    # 切分训练集和验证集节点\n",
    "    train_nodes, valid_nodes = train_test_split(list(range(len(vertex))), test_size=test_size, random_state=42)\n",
    "    train_nodes = tf.constant(train_nodes, dtype=tf.int32)[None,:] # 转换为张量，形状 (1, num_train_nodes)\n",
    "    valid_nodes = tf.constant(valid_nodes, dtype=tf.int32)[None,:] # 转换为张量，形状 (1, num_valid_nodes)\n",
    "\n",
    "    return graph, node_labels, train_nodes, valid_nodes, class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, node_labels, train_nodes, valid_nodes, class_map =\\\n",
    "    ch8.load_cora_nodetask_data(path='../source/data/graph/cora/', num_neighbors=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 子图采样方案**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当**图的规模很大时（例如超过百万节点，千万条边）**，一次性将整个图的信息加载到内存并进行计算可能是不可行的（**内存溢出**或**计算缓慢**），这时我们可以采用一种叫做**子图采样**的策略，**将全图以每个节点为中心，拆散为独立的子图，然后在每个子图上进行 GNN 模型的学习**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一种**从每个节点出发实现子图采样**的步骤大致如下：\n",
    "* 首先**以每个节点为中心**，开始将其周围的图结构信息收集，构成以节点为中心的子图，**每张子图与每个节点一一对应**，因此，我们可以用节点的索引作为子图的索引\n",
    "* 在考虑所要收集的子图规模时，通常考虑两个超参数：**跳数** $k$ 和 **邻居个数** `num_neighbors`\n",
    "  * 我们以节点为中心，递归地将周围邻居的连接信息加入子图，**直到** $k$ **跳的连接距离**\n",
    "  * 在构造子图时，我们会限制 `num_neighbors`，**邻居数超过** `num_neighbors` **的子图会做随机采样**\n",
    "* 以这种方式采样后，**子图的数量等于全图中节点的数量**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是子图采样的示意图"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap8/子图采样.png\" width=1000>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "子图采样后，**每个子图的学习是独立进行的，子图与子图之间没有连接关系**\n",
    "* 这带来的好处是，每个**节点的计算被限制在** $k$ **跳范围的子图上**，减少了全图信息传递所需的计算量，对全图做子图采样拆分后，也使得计算上可以利用批量处理的方式高效进行\n",
    "* 带来的缺点也很明显，我们**限制了每个节点能够进行通信的范围**，且子图之间是没有信息交互的，因此无论有多少层 GNN 特征提取层，**节点间的信息传递距离也无法超过子图采样时指定的跳数**\n",
    "  * 但在大部分的图学习实践中，往往**对节点推断最有帮助的信息都来自直接与它相连的邻居**\n",
    "  * 因此，子图采样虽然限制了模型性能的上限，但对于大部分任务，不会对性能造成灾难性的影响"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数 `node_subgraph_sampling()` 用于**实现上述从节点开始的子图采样**\n",
    "* 在确定每个子图的结构和信息后，我们在内部调用了上面的函数 `build_global_graph()`，从而**为每个子图创建节点索引、边索引、邻居索引、相连的边的索引**、并将其填充或截断到固定到固定的邻居数量 `num_neighbors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_subgraph_sampling(vertex, edges, vertex_feat, k_hops : int=1, \n",
    "                           num_neighbors : int=20, is_undirectional : bool=True):\n",
    "    graphs = [] # 存储子图的列表\n",
    "    \n",
    "    # 为每个节点设置索引\n",
    "    vertex_idx = {}\n",
    "    for i,node in enumerate(vertex):\n",
    "        vertex_idx[node] = i\n",
    "    \n",
    "    # 每个节点所连接的边的索引\n",
    "    edges, vertex_edge_loc = ch8.compute_vertex_edge_loc(vertex, edges)\n",
    "    \n",
    "    # 依次以每个节点为中心，采样其 k_hops 邻居构成子图\n",
    "    for i,node in enumerate(vertex):\n",
    "        subgraph = {} # 存储子图信息的字典\n",
    "\n",
    "        sub_vertex = [node] # 创建该子图的节点索引列表\n",
    "        sub_edges = [] # 创建该子图的边索引列表\n",
    "\n",
    "        # 该子图的节点特征\n",
    "        sub_vertex_feat = [vertex_feat[i]]\n",
    "\n",
    "        # 递归地采样 k_hops 邻居\n",
    "        end = 0\n",
    "        for _ in range(k_hops):\n",
    "            start, end = end, len(sub_vertex)\n",
    "            for j in range(start, end):\n",
    "                node_ = sub_vertex[j] # 当前处理的节点\n",
    "                \n",
    "                # 获取节点的邻居节点\n",
    "                l, r = vertex_edge_loc.get(node_, [-1, -1])\n",
    "\n",
    "                # 如果邻居数超过 num_neighbors，则随机采样 num_neighbors 个邻居\n",
    "                neighbors_list = list(range(l,r))\n",
    "                if len(neighbors_list) > num_neighbors:\n",
    "                    neighbors_list = np.random.choice(neighbors_list, num_neighbors, replace=False)\n",
    "\n",
    "                for idx in neighbors_list:\n",
    "                    # edges[idx][1] 是节点 node_ 的邻居节点\n",
    "                    from_node = edges[idx][1]\n",
    "\n",
    "                    # 防止重复添加节点\n",
    "                    if from_node not in sub_vertex:\n",
    "                        # 添加节点，以及节点的特征\n",
    "                        sub_vertex.append(from_node)\n",
    "                        sub_vertex_feat.append(vertex_feat[vertex_idx[from_node]])\n",
    "\n",
    "                    # 获取节点相连的边\n",
    "                    sub_edges.append(edges[idx])\n",
    "                \n",
    "        # 构造子图        \n",
    "        sub_vertex_idx, sub_edges_idx, sub_neighbors_idx, sub_connected_edges_idx, sub_valid_lens \\\n",
    "            = ch8.build_global_graph(vertex=sub_vertex, edges=sub_edges, num_neighbors=num_neighbors, is_undirectional=is_undirectional)\n",
    "        # 拆分出边的特征\n",
    "        sub_edges_feat = [edge[2] for edge in sub_edges_idx]\n",
    "        sub_edges_idx = [(edge[0], edge[1]) for edge in sub_edges_idx]\n",
    "\n",
    "        # 添加到子图信息中\n",
    "        subgraph[\"vertex_feat\"] = sub_vertex_feat\n",
    "        subgraph[\"edges_feat\"] = sub_edges_feat\n",
    "        subgraph[\"edges_idx\"] = sub_edges_idx\n",
    "        subgraph[\"neighbors_idx\"] = sub_neighbors_idx\n",
    "        subgraph[\"connected_edges_idx\"] = sub_connected_edges_idx\n",
    "        subgraph[\"valid_lens\"] = sub_valid_lens\n",
    "\n",
    "        graphs.append(subgraph) # 将子图添加到列表中\n",
    "    \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 1-跳 子图采样\n",
    "vertex, vertex_feat, vertex_class, edges, class_map = ch8.load_cora(path=\"../source/data/graph/cora/\")\n",
    "subgraphs = ch8.node_subgraph_sampling(vertex, edges, vertex_feat, k_hops=1, num_neighbors=20, is_undirectional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理子图采样后的数据，或者处理包含大量独立图的数据（例如**分子结构图，每个化学分子中原子的连接结构就构成一张独立的图**）时，我们就可以**像大部分深度学习数据的处理思路一样，将多个图 / 子图组装为一个批量**，便于利用 GPU 高效处理\n",
    "* 但注意每个**子图所包含的节点数量是不同的**，为了能够**把每个子图的这些特征和信息拼接为张量**，我们需要在**同一个批量中进行填充**\n",
    "* 让有关节点的张量具有形状 `(num_graph = batch_size, num_sub_nodes, ...)`，有关边的张量具有形状 `(num_graph = batch_size, num_sub_edges,...)`\n",
    "* `num_sub_nodes` 和 `num_sub_edges` 可以选择**批量中所有子图中节点数量和边数量的最大值**\n",
    "* 用全 0 向量来做填充，然后用 `valid_nodes` 和 `valid_edges` 来**记录每张子图的有效节点数和有效边数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用**子图采样的 GNN 接收下面几个输入**：\n",
    "* 关于**图的特征部分**：\n",
    "  * `subgraph[vertex_feat]`：节点特征张量，形状 `(num_graph, num_sub_nodes, num_feats)`\n",
    "  * `subgraph[edges_feat]`：边特征张量，形状 `(num_graph, num_sub_edges, num_feats)`\n",
    "  * `subgraph[graph_feat]`：全局图特征张量，形状 `(num_graph, num_feats)`\n",
    "    * 与全图处理的思路类似，如果**没有全图特征张量**，可以用每个子图中各节点特征向量的均值做初始化\n",
    "* 关于**图的结构部分**：\n",
    "  * `subgraph[edges_idx]`：边的连接关系，对应两端的节点索引，形状 `(num_graph, num_sub_edges, 2)`\n",
    "  * `subgraph[neighbors_idx]`：邻居节点索引张量，形状 `(num_graph, num_sub_nodes, num_neighbors)`\n",
    "  * `subgraph[connected_edges_idx]`：相连的边索引张量，形状 `(num_graph, num_sub_nodes, num_neighbors)`\n",
    "  * `subgraph[valid_lens]`：有效邻居个数，形状 `(num_graph, num_sub_nodes)`\n",
    "  * `subgraph[valid_nodes]`：每个子图的有效节点数，形状 `(num_graph, )`\n",
    "  * `subgraph[valid_edegs]`：每个子图的有效边数，形状 `(num_graph, )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的类 `GraphDataLoader` 用于实现**从多张图数据中通过填充组装为批量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader:\n",
    "    def __init__(self, graphs, labels=None, batch_size : int=64, shuffle : bool=False, \n",
    "                 num_node_feats : int=None, num_edge_feats : int=None, num_neighbors : int=None,\n",
    "                 removed_keys : list=None) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        graphs : list\n",
    "            存储子图信息的列表，每个元素为一个字典，字典中包含子图的信息\n",
    "        labels : list, default = None\n",
    "            图任务的标签，如果为 `None`，则表示无标签信息\n",
    "        batch_size : int, default = 64\n",
    "            批量大小\n",
    "        shuffle : bool, default = False\n",
    "            在迭代过程中是否打乱数据\n",
    "        num_node_feats : int, default = None\n",
    "            节点特征的维度，默认为 `None`，从图数据中自动获取\n",
    "        num_edge_feats : int, default = None\n",
    "            边特征的维度，默认为 `None`，从图数据中自动获取\n",
    "        num_neighbors : int, default = None\n",
    "            每个节点的邻居数，默认为 `None`，从图数据中自动获取\n",
    "        removed_keys : list, default = None\n",
    "            在处理和构造图数据时，不需要考虑的图信息\n",
    "        \"\"\"\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "        self.num_graphs = len(graphs)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        # 移除不需要的图信息\n",
    "        self.graph_keys = list(graphs[0].keys())\n",
    "        if removed_keys is not None:\n",
    "            for key in removed_keys:\n",
    "                self.graph_keys.remove(key)\n",
    "\n",
    "        # 准备填充的内容\n",
    "        self.num_node_feats = len(graphs[0][\"vertex_feat\"][0]) if num_node_feats is None else num_node_feats\n",
    "        self.num_neighbors = len(graphs[0][\"neighbors_idx\"][0]) if num_neighbors is None else num_neighbors\n",
    "\n",
    "        # 对于孤立点，有可能 edges_feat 是空列表，此时访问 graphs[0][\"edges_feat\"][0] 会报错\n",
    "        # 因此需要对 edges_feat 进行特殊处理，通过循环找到第一个非空列表，获取特征维度\n",
    "        if num_edge_feats is None:\n",
    "            for graph in graphs:\n",
    "                if len(graph[\"edges_feat\"]) > 0:\n",
    "                    self.num_edge_feats = len(graph[\"edges_feat\"][0])\n",
    "                    break\n",
    "        else:\n",
    "            self.num_edge_feats = num_edge_feats\n",
    "\n",
    "        # 在填充时，每个图信息要填充的内容\n",
    "        self.pad = {\n",
    "            \"vertex_feat\": [0] * self.num_node_feats,\n",
    "            \"edges_feat\": [0] * self.num_edge_feats,\n",
    "            \"edges_idx\": (-1, -1),\n",
    "            \"neighbors_idx\": [-1] * self.num_neighbors,\n",
    "            \"connected_edges_idx\": [-1] * self.num_neighbors,\n",
    "            \"valid_lens\": 0\n",
    "        }\n",
    "    \n",
    "    # 类的下标访问方法\n",
    "    def __getitem__(self, idx):\n",
    "        def add_batch_dim(graph):\n",
    "            for key in self.graph_keys:\n",
    "                graph[key] = tf.constant([graph[key]], dtype=tf.float32)\n",
    "                graph[key] = tf.expand_dims(graph[key], axis=0)\n",
    "        \n",
    "        # 将图信息转换为张量，并添加 batch 维度\n",
    "        graph = add_batch_dim(self.graphs[idx].copy())\n",
    "        if self.labels is not None:\n",
    "            return graph, self.labels[idx]\n",
    "        return graph\n",
    "    \n",
    "    # 类的 len 方法 \n",
    "    def __len__(self):\n",
    "        return self.num_graphs\n",
    "    \n",
    "    # 类的迭代器方法\n",
    "    def __iter__(self):\n",
    "        return self.create_dataset(self.shuffle).__iter__()\n",
    "    \n",
    "    # 填充辅助函数，用变量 pad 填充列表 info，使其长度为 max_len\n",
    "    def pad_info(self, info : list, pad, max_len : int):\n",
    "        info += [pad for _ in range(max_len - len(info))]\n",
    "        return info\n",
    "    \n",
    "    def create_dataset(self, shuffle : bool=False):\n",
    "        def padded_batch_generator():\n",
    "            # 如果 shuffle 为 True，则打乱数据\n",
    "            idx = np.random.permutation(self.num_graphs) if shuffle else np.arange(self.num_graphs)\n",
    "\n",
    "            for i in range(0, self.num_graphs, self.batch_size):\n",
    "                # 选取 batch_size 个图\n",
    "                graph_batch = {} # 存储当前 batch 中图的信息\n",
    "                for key in self.graph_keys:\n",
    "                    # 这里用 copy() 是为了防止修改原始数据\n",
    "                    graph_batch[key] = [self.graphs[j][key].copy() for j in idx[i:i+self.batch_size]]\n",
    "                \n",
    "                if self.labels is not None:\n",
    "                    labels_batch = [self.labels[j] for j in idx[i:i+self.batch_size]] # 存储当前 batch 中图的标签\n",
    "\n",
    "                # 进行填充\n",
    "                num_sub_nodes = max([len(x) for x in graph_batch[\"vertex_feat\"]]) # 子图中最大节点数\n",
    "                num_sub_edges = max([len(x) for x in graph_batch[\"edges_feat\"]]) # 子图中最大边数\n",
    "                \n",
    "                batch_size = len(graph_batch[\"vertex_feat\"]) # 当前 batch 中图的数量\n",
    "\n",
    "                valid_nodes, valid_edges = [], [] # 记录每个图的有效节点数和有效边数\n",
    "                \n",
    "                # 节点信息填充\n",
    "                for b in range(batch_size):\n",
    "                    valid_nodes.append(len(graph_batch[\"vertex_feat\"][b]))\n",
    "                    for key in [\"vertex_feat\", \"neighbors_idx\", \"connected_edges_idx\", \"valid_lens\"]:\n",
    "                        graph_batch[key][b] = self.pad_info(graph_batch[key][b], self.pad[key], num_sub_nodes)\n",
    "                        \n",
    "                # 边信息填充\n",
    "                for b in range(batch_size):\n",
    "                    valid_edges.append(len(graph_batch[\"edges_idx\"][b]))\n",
    "                    for key in [\"edges_feat\", \"edges_idx\"]:\n",
    "                        graph_batch[key][b] = self.pad_info(graph_batch[key][b], self.pad[key], num_sub_edges)\n",
    "                        \n",
    "                # 将填充后的列表拼装成张量\n",
    "                for key in self.graph_keys:\n",
    "                    graph_batch[key] = tf.stack(graph_batch[key])\n",
    "                graph_batch[\"valid_nodes\"] = tf.constant(valid_nodes)\n",
    "                graph_batch[\"valid_edges\"] = tf.constant(valid_edges)\n",
    "                \n",
    "                if self.labels is not None:\n",
    "                    yield (graph_batch, tf.constant(labels_batch))\n",
    "                else:\n",
    "                    yield graph_batch\n",
    "        \n",
    "        # 创建 TensorFlow 数据集\n",
    "        # 创建 Signature 标注输出的数据格式\n",
    "        output_signature = {\n",
    "                \"vertex_feat\": tf.TensorSpec(shape=(None, None, self.num_node_feats)),\n",
    "                \"edges_feat\": tf.TensorSpec(shape=(None, None, self.num_edge_feats)),\n",
    "                \"edges_idx\": tf.TensorSpec(shape=(None, None, 2), dtype=tf.int32),\n",
    "                \"neighbors_idx\": tf.TensorSpec(shape=(None, None, self.num_neighbors), dtype=tf.int32),\n",
    "                \"connected_edges_idx\": tf.TensorSpec(shape=(None, None, self.num_neighbors), dtype=tf.int32),\n",
    "                \"valid_lens\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "                \"valid_nodes\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                \"valid_edges\": tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            output_signature = (output_signature, tf.TensorSpec(shape=(None,)))\n",
    "\n",
    "        # 使用 from_generator 方法创建数据集\n",
    "        dataset = tf.data.Dataset.from_generator(padded_batch_generator, output_signature=output_signature)\n",
    "        # prefetch 通过异步的方式让数据集准备好，提高效率\n",
    "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 个批量 vertex_feat          的形状： (64, 20, 1433)\n",
      "第 1 个批量 edges_feat           的形状： (64, 38, 1)\n",
      "第 1 个批量 edges_idx            的形状： (64, 38, 2)\n",
      "第 1 个批量 neighbors_idx        的形状： (64, 20, 20)\n",
      "第 1 个批量 connected_edges_idx  的形状： (64, 20, 20)\n",
      "第 1 个批量 valid_lens           的形状： (64, 20)\n",
      "第 1 个批量 valid_nodes          的形状： (64,)\n",
      "第 1 个批量 valid_edges          的形状： (64,)\n",
      "============================================================\n",
      "第 2 个批量 vertex_feat          的形状： (64, 21, 1433)\n",
      "第 2 个批量 edges_feat           的形状： (64, 40, 1)\n",
      "第 2 个批量 edges_idx            的形状： (64, 40, 2)\n",
      "第 2 个批量 neighbors_idx        的形状： (64, 21, 20)\n",
      "第 2 个批量 connected_edges_idx  的形状： (64, 21, 20)\n",
      "第 2 个批量 valid_lens           的形状： (64, 21)\n",
      "第 2 个批量 valid_nodes          的形状： (64,)\n",
      "第 2 个批量 valid_edges          的形状： (64,)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 生成子图数据迭代器\n",
    "batch_size = 64\n",
    "subgraph_loader = GraphDataLoader(subgraphs, batch_size=batch_size, shuffle=False)\n",
    "subgraph_dataset = subgraph_loader.create_dataset()\n",
    "# 打印查看子图数据的形状\n",
    "for i, graph_batch in enumerate(subgraph_dataset.take(2)):\n",
    "    for key in graph_batch.keys():\n",
    "        print(\"第 %d 个批量 %-20s 的形状：\"%(i+1,key),graph_batch[key].shape)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，我们可以具体拿到批量数据中，某个子图的相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "子图有效节点数： tf.Tensor(7, shape=(), dtype=int32)\n",
      "子图有效边数： tf.Tensor(12, shape=(), dtype=int32)\n",
      "节点特征：\n",
      " tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(7, 1433), dtype=float32)\n",
      "边连接关系：\n",
      " tf.Tensor(\n",
      "[[0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [0 4]\n",
      " [0 5]\n",
      " [0 6]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [3 0]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [6 0]], shape=(12, 2), dtype=int32)\n",
      "邻居节点索引：\n",
      " tf.Tensor(\n",
      "[[ 1  2  3  4  5  6 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]], shape=(7, 20), dtype=int32)\n",
      "相连接的边的索引：\n",
      " tf.Tensor(\n",
      "[[ 0  1  2  3  4  5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 6 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 7 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 8 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 9 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [10 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [11 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]], shape=(7, 20), dtype=int32)\n",
      "有效邻居数：\n",
      " tf.Tensor([6 1 1 1 1 1 1], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "graph_idx = 6 # 子图索引\n",
    "num_nodes = graph_batch[\"valid_nodes\"][graph_idx] # 子图有效节点数\n",
    "num_edges = graph_batch[\"valid_edges\"][graph_idx] # 子图有效边数\n",
    "print(\"子图有效节点数：\", num_nodes)\n",
    "print(\"子图有效边数：\", num_edges)\n",
    "print(\"节点特征：\\n\", graph_batch[\"vertex_feat\"][graph_idx][:num_nodes])\n",
    "print(\"边连接关系：\\n\", graph_batch[\"edges_idx\"][graph_idx][:num_edges])\n",
    "print(\"邻居节点索引：\\n\", graph_batch[\"neighbors_idx\"][graph_idx][:num_nodes])\n",
    "print(\"相连接的边的索引：\\n\", graph_batch[\"connected_edges_idx\"][graph_idx][:num_nodes])\n",
    "print(\"有效邻居数：\\n\", graph_batch[\"valid_lens\"][graph_idx][:num_nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时在**使用这种批量图数据在 GNN 层中进行消息传递**，通过 `tf.gather()` 收集邻居节点特征时，**由于数据中的第一个维度是批量维度，需要指定 `batch_dims=1`**\n",
    "* 注意一个批量的有很多信息是填充得到的，**如果需要过滤，可以借助 `valid_nodes`，`valid_edges`，`valid_lens` 进行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 21, 20, 1433])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在子图数据中，收集每个节点的邻居节点特征\n",
    "# neighbors_feat 的形状 (num_graph, num_sub_nodes, num_neighbors, num_node_feats)\n",
    "neighbors_feat = tf.gather(graph_batch[\"vertex_feat\"], graph_batch[\"neighbors_idx\"], batch_dims=1)\n",
    "neighbors_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 21, 1433])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 聚合邻居节点特征\n",
    "neighbors_feat = tf.reduce_sum(neighbors_feat, axis=2) # 形状 (num_graph, num_sub_nodes, num_node_feats)\n",
    "neighbors_feat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **练习**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过两个子图采样的练习，来提升图数据的处理能力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在子图采样中，我们展示了**以节点为中心开始向四周扩展的子图采样策略**，这适用于节点相关的预测任务，而**当预测任务是关于图中的边时，我们可以尝试以边为中心开始向四周扩展的子图采样**，基于该思想，仿照 `node_subgraph_sampling()` 的逻辑，实现 `edge_subgraph_sampling()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 在链接预测任务（**Link Prediction**）中，**给定图 $G$ 中的两个节点 $u,v$，我们希望预测结点 $u,v$ 之间是否应该存在连接关系**，当图的规模较大时，我们同样需要借助子图采样，但此时的采样逻辑为：\n",
    "    * 选择采样跳数 `k_hops`，**分别从 $u,v$ 出发，采样 $u,v$ 周围的图结构信息**，它们共同构成一张完整的图（**注意，此时图可能是不连通的两个子图**）\n",
    "    * 我们将采集得到的图结构**称为关于结点 $u,v$ 的封闭子图 $\\overline{G}(u,v)$**\n",
    "    * 在 GNN 建模中，该封闭子图 $\\overline{G}(u,v)$ 的全图特征可以用于预测 $u,v$ 之间是否存在连接关系\n",
    "\n",
    "    定义函数 `link_prediction_subgraph_sampling()` 来实现上述逻辑，函数接口定义如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction_subgraph_sampling(vertex, edges, u, v, k_hops : int):\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 结合图结构 / 图数据的特点，以及本节介绍的几种图任务，谈一谈图模型在实际中还有哪些应用场景"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
