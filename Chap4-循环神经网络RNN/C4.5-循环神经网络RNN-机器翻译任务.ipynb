{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chap4：循环神经网络RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 11:03:33.433608: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 11:03:33.583149: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-10 11:03:33.615337: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-10 11:03:34.365372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/envs/tensorflow/lib/\n",
      "2023-07-10 11:03:34.365459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/lib/:/home/chenguangze/software/miniconda3/envs/tensorflow/lib/\n",
      "2023-07-10 11:03:34.365466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from source.code import ch4\n",
    "from source.code import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你要在服务器上和别人共用GPU，可以设置你需要的显存资源\n",
    "utils.gpu_limitation_config(memory=30,device=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.5 机器翻译任务**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5.1 数据集准备**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 数据集导入**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们展示另一种NLP中的常见任务，**机器翻译**，我们将演示**英文到中文的翻译**，首先，导入中英文平行对照文件 `../source/data/news_v16-en-zh.tsv`\n",
    "* 每一行是一个句子对，中间用 `\"\\t\"` 隔开\n",
    "* **机器翻译相关的数据集可以在各开源网站找到，或者自己制作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源语句： 1929 or 1989?\n",
      "目标语句： 1929年还是1989年?\n",
      "\n",
      "源语句： PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.\n",
      "目标语句： 巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正在发生的情况。\n",
      "\n",
      "源语句： At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.\n",
      "目标语句： 一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为这两段时期意味着典型的周期性衰退。\n",
      "\n",
      "源语句： Today, the mood is much grimmer, with references to 1929 and 1931 beginning to abound, even if some governments continue to behave as if the crisis was more classical than exceptional.\n",
      "目标语句： 如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政府的表现仍然似乎把视目前的情况为是典型的而看见的衰退。\n",
      "\n",
      "源语句： The tendency is either excessive restraint (Europe) or a diffusion of the effort (the United States).\n",
      "目标语句： 目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"../source/data/translation/news_v16-en-zh.tsv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for i in range(5):\n",
    "        line = file.readline()\n",
    "        # 分别获取英文，中文\n",
    "        en, zh = line.split(\"\\t\")\n",
    "        print(\"源语句：\", en)\n",
    "        print(\"目标语句：\", zh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 预处理和词元化**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要对文本序列进行**预处理**，并准备将中文和英文分别**词元化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_en_zh(file : str, num_lines : int = None):\n",
    "    \"\"\"\n",
    "    预处理英文-中文数据集\n",
    "    \"\"\"\n",
    "    import re, jieba\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(\",.!?:()‘’“”\") and prev_char != \" \"\n",
    "    \n",
    "    # 打开读取文件\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    num_lines = num_lines if num_lines is not None else len(lines)\n",
    "\n",
    "    source, target = [], [] # 保存源语句和目标语句\n",
    "\n",
    "    for line in tqdm(lines[:num_lines]):\n",
    "        # 分别获取英文，中文\n",
    "        en, zh = line.split(\"\\t\")\n",
    "\n",
    "        # 英文预处理\n",
    "        # 1. '\\u202f' 和 '\\xa0' 替换为普通空格\n",
    "        en = en.replace(\"\\u202f\", \" \").replace(\"\\xa0\", \" \")\n",
    "        # 2. 全部转换为小写\n",
    "        en = en.lower()\n",
    "        # 3. 在单词和标点符号之间添加空格(在标点符号前添加空格，为了利用空格分词)\n",
    "        en = [' ' + char if i > 0 and no_space(char, en[i - 1]) else char for i, char in enumerate(en)]\n",
    "        en = ''.join(en)\n",
    "        # 4. 利用空格分词\n",
    "        en = en.split()\n",
    "\n",
    "        # 中文预处理\n",
    "        # 1. 用中文标点替换英文标点\n",
    "        zh = zh.replace(\",\", \"，\").replace(\".\", \"。\").replace(\"?\", \"？\").replace(\"!\", \"！\")\n",
    "        # 1. 用正则表达式保留中文字符\n",
    "        zh = re.sub(r\"[^\\u4e00-\\u9fa5，、。？！；：（）《》‘’”“0-9]\", '', zh)\n",
    "        # 2. 利用 jieba 分词\n",
    "        zh = list(jieba.lcut(zh))\n",
    "\n",
    "        # 将处理后的数据添加到列表中\n",
    "        if 0 < len(en) < 100 and 0 < len(zh) < 100:\n",
    "            source.append(en)\n",
    "            target.append(zh)\n",
    "\n",
    "    return source, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "备注：source和target是2D列表，每个元素都是一个句子的分词结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/322275 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.830 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 322275/322275 [01:39<00:00, 3223.29it/s]\n"
     ]
    }
   ],
   "source": [
    "source, target = ch4.preprocessing_en_zh(file=\"../source/data/translation/news_v16-en-zh.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英语词元： ['1929', 'or', '1989', '?']\n",
      "中文词元： ['1929', '年', '还是', '1989', '年', '？']\n"
     ]
    }
   ],
   "source": [
    "print(\"英语词元：\",source[0])\n",
    "print(\"中文词元：\",target[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们绘制每个文本序列所包含的词元数量的直方图**，这可以帮助我们确认在训练时，**统一模型所处理文本序列的长度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentence_length_hist(source : list, target : list):\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "    # 统计英文和中文的句子长度\n",
    "    source_len = [len(sen) for sen in source]\n",
    "    target_len = [len(sen) for sen in target]\n",
    "\n",
    "    # 绘制英文和中文的句子长度直方图\n",
    "    _,_,patches = plt.hist([source_len, target_len], bins=10, label=[\"source\", \"target\"])\n",
    "    # 显示条纹\n",
    "    for patch in patches[1]:\n",
    "        patch.set_hatch('///')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"# tokens per sentence\")\n",
    "    plt.ylabel(\"frequency\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以观察到：\n",
    "* 绝大部分序列，**词元化后的长度都小于 60**\n",
    "* 对于大部分序列，**词元化后的长度介于 20 至 30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ch4.plot_sentence_length_hist(source, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 创建词表**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，使用我们之前定义的 `Vocab` 类创建**中英文词表** `en_vocab` 和 `zh_vocab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 英文词表\n",
    "en_vocab = ch4.Vocab(source, min_freq=2)\n",
    "# 中文词表\n",
    "zh_vocab = ch4.Vocab(target, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文词表大小： 52619\n",
      "中文词表大小： 54082\n"
     ]
    }
   ],
   "source": [
    "# 词表大小\n",
    "print(\"英文词表大小：\", len(en_vocab))\n",
    "print(\"中文词表大小：\", len(zh_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) 创建数据集**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语言模型中的**序列样本都有一个固定的长度** `num_steps`，即**时间步数**，无论这个样本是一个句子，或是句子的一部分，或横跨了多个句子，在**机器翻译**任务中，**每个样本是由源语句和目标语句组成的文本序列对**\n",
    "* 不管来自源语句还是目标语句，每个文本序列可能具有不同的长度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了提高处理效率，让模型的计算变得简单，我们可以通过**截断**（truncate）和**填充**（padding）来**将所有的文本序列处理成为相同的长度** `num_steps`，这样**便于将文本数据制作成为批量供模型使用**\n",
    "* 当文本序列的词元数目少于 `num_steps` 时，我们在其末尾添加特殊词元 `<pad>`\n",
    "* 当文本序列的词元数目超过 `num_steps` 时，我们将截断文本序列超出 `num_steps` 的部分，丢弃剩余词元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_padding(line : list, num_steps : int, padding_token : int):\n",
    "    \"\"\"\n",
    "    截断或者填充句子\n",
    "    \"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        # 截断句子\n",
    "        return line[:num_steps]\n",
    "    else:\n",
    "        # 填充句子\n",
    "        return line + [padding_token] * (num_steps - len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始词元： ['1929', 'or', '1989', '?']\n",
      "词元索引： [6725, 41, 2721, 96]\n",
      "截断和填充后词元索引： [6725, 41, 2721, 96, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# 截断或者填充句子到 10 个词元\n",
    "sentence = source[0]\n",
    "# 转换为索引\n",
    "sentence_idx = en_vocab[sentence]\n",
    "sentence_done = ch4.truncate_padding(line=en_vocab[source[0]], num_steps=10, padding_token=en_vocab[\"<pad>\"])\n",
    "\n",
    "print(\"原始词元：\", sentence)\n",
    "print(\"词元索引：\", sentence_idx)\n",
    "print(\"截断和填充后词元索引：\", sentence_done)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们定义一个函数 `build_translation_array()`，可以**将文本序列转换成小批量数据集用于训练**，我们将特定的词元 `<eos>` **添加到所有序列的末尾**，用于表示一段序列的结束\n",
    "* 在翻译时，这能让模型通过一个词元接一个词元地生成序列进行预测时，生成到 `<eos>` 时意识到**序列生成工作结束**\n",
    "* 此外，我们统计**每个文本序列的有效长度** `valid_len` ，**统计长度时去除了填充词** `<pad>`，在之后介绍的模型中会需要这个长度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_translation_array(tokens : list, vocab, num_steps):\n",
    "    \"\"\"\n",
    "    将文本序列转换为训练用的批量数据\n",
    "    \"\"\"\n",
    "    # 将文本词元转换为词元索引\n",
    "    tokens = [vocab[line] for line in tokens] # 字符串数值化\n",
    "    # 在句子末尾添加结束标记 <eos>\n",
    "    tokens = [line + [vocab[\"<eos>\"]] for line in tokens]\n",
    "\n",
    "    # 对句子进行截断和填充，转换为张量\n",
    "    array = tf.constant([ch4.truncate_padding(line, num_steps, vocab[\"<pad>\"]) for line in tokens])\n",
    "    # 统计每个句子的有效长度\n",
    "    valid_len = tf.reduce_sum(tf.cast(array != vocab[\"<pad>\"], tf.int32), axis=1)\n",
    "\n",
    "    return array, valid_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**把所有的功能**用函数 `load_translation_en_zh` 进行封装，创建我们的数据迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_translation_en_zh(file : str, batch_size : int, num_steps : int, num_lines : int=None):\n",
    "    \"\"\"\n",
    "    ### 加载英文-中文翻译数据集\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        数据集文件路径\n",
    "    batch_size : int\n",
    "        批量大小\n",
    "    num_steps : int\n",
    "        每个句子的时间步\n",
    "    num_lines : int\n",
    "        读取的行数\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_iter : tf.data.Dataset\n",
    "        数据集迭代器\n",
    "    src_vocab : Vocab\n",
    "        源语言词表\n",
    "    tgt_vocab : Vocab\n",
    "        目标语言词表\n",
    "    \"\"\"\n",
    "    # 读取数据集\n",
    "    source, target = ch4.preprocessing_en_zh(file,num_lines)\n",
    "    # 构建词表\n",
    "    src_vocab = ch4.Vocab(source, min_freq=2)\n",
    "    tgt_vocab = ch4.Vocab(target, min_freq=2)\n",
    "    # 构建数据集\n",
    "    src_array, src_valid_len = ch4.build_translation_array(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = ch4.build_translation_array(target, tgt_vocab, num_steps)\n",
    "\n",
    "    # 构建数据集，包含四个元素\n",
    "    dataset = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    # 创建迭代器\n",
    "    data_iter = tf.data.Dataset.from_tensor_slices(dataset).batch(batch_size).shuffle(batch_size)\n",
    "\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试各个函数接口工作是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322275/322275 [01:40<00:00, 3210.05it/s]\n",
      "2023-06-20 20:24:15.860600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 20:24:21.587415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30963 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.588824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 984 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.590436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30963 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3d:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.591600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30963 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.592809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30963 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:88:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.594013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30963 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.595190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30963 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2023-06-20 20:24:21.596427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30963 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tf.Tensor(\n",
      "[[ 6725    41  2721    96     2     3     3     3     3     3]\n",
      " [  837    16    18     5    49   113 11488     9 19311     4]], shape=(2, 10), dtype=int32)\n",
      "X的有效长度: tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "Y: tf.Tensor(\n",
      "[[6792   25  273 2619   25   91    2    3    3    3]\n",
      " [ 909  299 1599  377 3108    7 2452    5  480   68]], shape=(2, 10), dtype=int32)\n",
      "Y的有效长度: tf.Tensor([ 7 10], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_iter, src_vocab, tgt_vocab = ch4.load_translation_en_zh(\n",
    "    file=\"../source/data/translation/news_v16-en-zh.tsv\",batch_size=2, num_steps=10)\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    print('X:', tf.cast(X, tf.int32))\n",
    "    print('X的有效长度:', X_valid_len)\n",
    "    print('Y:', tf.cast(Y, tf.int32))\n",
    "    print('Y的有效长度:', Y_valid_len)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5.2 编码器和解码器模型**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器翻译所要实现的是一个**序列转换**（从源语句，翻译到目标语句），其**输入和输出都是长度可变的序列**，为了处理这种**输入和输出有差异的问题**，人们设计了包含两个组件的**编码器-解码器**模型架构：\n",
    "* **编码器**（**encoder**）：接收一个**长度可变**的序列作为输入，并将其转换为**具有固定形状的编码状态**\n",
    "* **解码器**（**decoder**）：接收**编码器编码**得到的**固定形状的编码状态**作为输入，然后映射到**长度可变的输出序列**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编码器-解码器**架构如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/编码器解码器.svg\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们机器翻译的例子中：\n",
    "* 给定输入序列 \"How are you today ?\"，**编码器会将句子包含的语义信息编码到一个状态** $H$\n",
    "* 解码器**接收这个状态** $H$，然后一个词接一个词的生成翻译结果 \"你今天怎么样？\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编码器-解码器**的这种基本思想现在已经成为很多深度学习模型的基本框架\n",
    "* 例如**文本生成图像**的模型，可以设计一个编码器将用户的绘图需求文本转换到隐状态，然后让解码器将这个隐状态解码为图像输出"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一节，我们先定义几个抽象的类 `Encoder`，`Decoder` 和 `EncoderDecoder` 来演示**编码器-解码器**模型的工作流程\n",
    "* 后续基于**编码器-解码器**架构实现的模型，可以直接继承这几个抽象类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 编码器**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在编码器接口中，我们只指定长度可变的序列作为编码器的输入 `inputs`\n",
    "* 任何继承这个 `Encoder` 基类的模型将完成模型的推理逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 解码器**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在解码器接口中：\n",
    "* 我们新增一个 `init_state()` 函数，它用于将**编码器的输出** `enc_outputs` **转换为编码后的状态**\n",
    "* `init_state()` 可能需要额外的输入，例如**输入序列的有效长度** `valid_len`\n",
    "* 为了逐个生成长度可变的词元序列，解码器在每个时间步都会将**输入** `inputs`（例如上一个时间步的词元） 和**编码后的状态** `state` **映射成当前时间步的输出词元**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_len=None, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def call(self, inputs, state, *args, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 合并编码器-解码器**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编码器-解码器**架构包含了**一个编码器和一个解码器**\n",
    "* 模型还拥有可选的额外的参数（例如**有效长度** `valid_len`），包含在 `call()` 方法的 `*args, **kwargs` 中\n",
    "* 在前向传播中，**编码器的输出用于生成编码状态**，这个状态又**被解码器作为其输入的一部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def call(self, enc_inputs, dec_inputs, *args, **kwargs):\n",
    "        # 编码器负责将输入序列编码为隐状态\n",
    "        enc_outputs = self.encoder(enc_inputs, *args, **kwargs)\n",
    "        # 解码器负责根据编码器的输出和输入序列来预测输出序列\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_inputs, dec_state, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器和解码器相关的三个类 `Encoder`，`Decoder`，`EncoderDecoder` 已经写入了 `../source/code/utils.py` 中，下面我们将演示借助 RNN 来实现一个具体的**编码器-解码器机器翻译模型**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5.3 用 RNN 实现机器翻译模型**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节，我们用两个循环神经网络的**编码器-解码器**模型，实现机器翻译任务的这种**序列到序列**（sequence to sequence，称为**seq2seq**）的学习任务\n",
    "* RNN 编码器使用长度可变的序列作为输入，将其**转换为固定形状的隐状态** $H$\n",
    "* 换言之，**输入序列的信息被编码到隐状态中**，这个隐状态大家又称为**上下文信息**\n",
    "* 为了连续生成输出序列的词元，另一个 RNN 模型作为解码器，**基于输入序列的编码信息**，和**输出序列已经看见的或者已经生成的词元**来预测下一个词元"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个模型结构如下图所示：\n",
    "* 特定的词元 `<eos>` 表示**序列结束**，一旦模型输出 `<eos>` 就停止预测\n",
    "* 在 RNN 解码器的**初始化时间步**，我们将特殊词元 `<bos>`（表示**序列开始**）作为 $t=1$ 时刻的观测，用来预测下一个待翻译的词\n",
    "* 我们可以使用**RNN 编码器最终的隐状态**来**初始化 RNN 解码器的隐状态**，以便**将编码器收集到的源语句的上下文信息传递给解码器使用**\n",
    "* 或者，我们也可以将**RNN 编码器最终的隐状态作为 RNN 解码器输入特征的一部分**\n",
    "* **真实的翻译结果作为标签**，RNN 解码器不断向后预测下一个词元，然后计算损失函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/RNN编码器解码器.png\" width=800>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们具体看模型的实现细节"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 编码器**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用 RNN 设计编码器，它**将长度可变的输入序列转换为形状固定的上下文状态变量** $c$，输入序列的有用信息全部被编码到 $c$ 中，考虑批量为 1 输入词元序列 $x_1,\\cdots,x_T$，在时间步 $t$，RNN 将 $x_t$ 和上一时间步的隐藏状态 $h_{t-1}$ 变换到 $h_t$，我们用某个抽象的函数 $f$ 表示 RNN 实现的这种变换：\n",
    "$$\n",
    "h_t = f(x_t,h_{t-1})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总之，**RNN 编码器需要通过拟合某个函数** $q$，**将所有时间步的隐藏状态转换为上下文变量** $c$：\n",
    "$$\n",
    "c = q(h_1,\\cdots,h_T)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如一种最简单的方式是选择 $q(h_1,\\cdots,h_T) = h_T$，则**下文变量仅仅是输入序列在最后时间步的隐状态**，到目前为止：\n",
    "* 我们使用的是一个**单向循环神经网络**来设计编码器，隐状态 $h_t$ 只依赖于时间步 $t$ 及其之前的子序列信息（**包含之前的隐状态**）\n",
    "* 我们也可以使用**双向循环神经网络构造编码器**，此时**隐状态会依赖于前向递推和后向递推得到的两个输入子序列**，因此隐状态 $h_t$ **对整个序列的信息都进行了编码**\n",
    "* 思考，在**机器翻译**任务中，我们永远能够**看到完整的源语言文本**，而不像之前文本预测任务中那样只看到上文预测下文，所以**编码器使用双向循环神经网络是合理的**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来实现 RNN 编码器：\n",
    "* 我们使用一个**嵌入层**将源语言词元映射到源语言的词空间\n",
    "* RNN 模型选择了**多层的双向 GRU 模型**，你也可以更改为 LSTM\n",
    "* 在实现时，请明晰每一层的计算逻辑，以及**模型所涉及的隐藏状态有哪些**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 编码器\n",
    "class Seq2SeqEncoder(utils.Encoder):\n",
    "    def __init__(self, vocab_size : int, embed_size : int, \n",
    "                 num_hiddens : int, num_layers : int, dropout : float=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        from keras.layers import Embedding, GRU, Bidirectional\n",
    "        # 嵌入层\n",
    "        self.embedding = Embedding(vocab_size, embed_size)\n",
    "        # RNN 层\n",
    "        self.rnn_layers = []\n",
    "        for i in range(num_layers):\n",
    "            self.rnn_layers.append(Bidirectional(\n",
    "                GRU(num_hiddens, return_sequences=True, return_state=True, dropout=dropout)))\n",
    "    \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        # 输入形状：(batch_size, num_steps)\n",
    "        X = self.embedding(inputs) # 先进行词嵌入\n",
    "\n",
    "        # 保存每一层最终的隐状态\n",
    "        state = []\n",
    "        for layer in self.rnn_layers:\n",
    "            X, *layer_state = layer(X,**kwargs)\n",
    "            state.append(layer_state) # 保存每一层的隐状态\n",
    "        \n",
    "        return X, state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们实例化编码器，并进行简单的实验，观察输出形状的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状： (4, 7, 32)\n",
      "编码器 RNN 层数： 2\n",
      "第一层隐藏状态数量： 2\n",
      "第一层前向隐藏状态形状： (4, 16)\n"
     ]
    }
   ],
   "source": [
    "# 解码器词表大小，嵌入大小，隐藏单元个数，层数\n",
    "vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2\n",
    "encoder = ch4.Seq2SeqEncoder(vocab_size=vocab_size, embed_size=embed_size, \n",
    "                             num_hiddens=num_hiddens, num_layers=num_layers)\n",
    "# 输入序列特征\n",
    "X = tf.zeros((4, 7)) # (batch_size, num_steps)\n",
    "\n",
    "# 输出和隐藏状态\n",
    "Y, state = encoder(X,training=False)\n",
    "print(\"输出形状：\", Y.shape) # (batch_size, num_steps, 2*num_hiddens)\n",
    "print(\"编码器 RNN 层数：\", len(state)) # num_layers\n",
    "print(\"第一层隐藏状态数量：\", len(state[0])) # 有两个隐藏状态，分别是前向和后向的隐藏状态\n",
    "print(\"第一层前向隐藏状态形状：\", state[0][0].shape) # (batch_size, num_hiddens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 解码器**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器输出的上下文变量 $c$ 对整个输入序列 $x_1,\\cdots,x_T$ 进行编码，来自训练数据的输出序列 $y_1,y_2,\\cdots,y_{T'}$ 对于每个时间步 $t'$（注意**这与输入序列的时间步** $t$ **没有关系**），解码器输出 $y_{t'}$ 的概率**取决于先前的输出子序列** $y_1,y_2,\\cdots,y_{t'-1}$ 和**上下文变量** $c$：\n",
    "$$\n",
    "P(y_{t'} | y_1,\\cdots,y_{t'-1},c)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了在序列上模型化这种条件概率，我们可以**使用另一个 RNN 作为解码器**，在输出序列的时间步 $t'$ 上\n",
    "* RNN 将来自**上一时间步的输出** $y_{t'-1}$ 和**上下文变量** $c$ 作为其输入，上下文变量 $c$ **选取为 RNN 编码器最后一层隐状态**\n",
    "    * 如果编码器使用了双向 RNN，则**最后一层包含两个隐藏状态**，可以把它们拼接在一起使用\n",
    "* 然后**在当前时间步将它们**（$y_{t'-1}$ 和 $c$）和**上一时间步解码器的隐藏状态** $s_{t'-1}$ 转换为新的隐状态 $s_{t'}$\n",
    "* 我们用抽象函数 $g$ 表示这种变换：\n",
    "$$\n",
    "s_{t'} = g(y_{t'-1},c,s_{t'-1})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得最后的隐藏状态后，把它接入**输出层**和 `softmax` 变换，就可以得到目标词元 $y_{t'}$ 的概率分布了"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面解码器的实现中，，注意一些细节：\n",
    "* 我们**使用编码器最后一个时间步的隐状态来初始化解码器的隐状态**\n",
    "    * 首先，这要求**RNN 编码器和 RNN 解码器具有相同数量的层和隐藏单元**\n",
    "    * 如果 RNN 编码器使用了**双向模型**，则**每层会包含两个隐藏状态**，这时候有两种处理思路：\n",
    "        * 选择其中一个，例如前向隐状态，去初始化 RNN 解码器的隐状态\n",
    "        * 将两个隐状态拼接在一起使用，则此时要求 **RNN 解码器的隐藏单元数量是 RNN 编码器的两倍**\n",
    "* 为了让**经过编码的输入序列的信息在每个时间步都能利用**，上下文变量 $c$ **在所有时间步与解码器的输入进行拼接**\n",
    "* 为了预测输出词元的概率分布，在 RNN 解码器的**最后一层使用全连接层来变换隐状态**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(utils.Decoder):\n",
    "    def __init__(self, vocab_size : int, embed_size : int, \n",
    "                 num_hiddens : int, num_layers : int, dropout : float=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        from keras.layers import Embedding, GRU, Dense\n",
    "        # 嵌入层\n",
    "        self.embedding = Embedding(vocab_size, embed_size)\n",
    "        # RNN 层\n",
    "        self.rnn_layers = []\n",
    "        for i in range(num_layers):\n",
    "            self.rnn_layers.append(GRU(num_hiddens, return_sequences=True, return_state=True, dropout=dropout))\n",
    "        # 输出层\n",
    "        self.dense = Dense(vocab_size, activation='softmax')\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_len=None, *args, **kwargs):\n",
    "        # enc_outputs 包含两个元素：Y 和 state\n",
    "        # Y 是编码器最后一层的输出，形状：(batch_size, num_steps, 2*num_hiddens)\n",
    "        # state 是编码器每一层最后时间步的隐藏状态组成的列表\n",
    "            # 如果编码器是单向 RNN，则每个元素形状：(batch_size, num_hiddens)\n",
    "            # 如果编码器是双向 RNN，则包含两个隐状态，每个形状：(batch_size, num_hiddens)\n",
    "        # 返回一个包含 num_layers 个元素的列表\n",
    "        state = enc_outputs[1]\n",
    "\n",
    "        # 我们将前向和后向的隐藏状态拼接在一起\n",
    "        # 现在每个元素的形状：(batch_size, 2*num_hiddens)\n",
    "        state = [tf.concat(layer_state, axis=-1) for layer_state in state]\n",
    "        return state\n",
    "\n",
    "    def call(self, inputs, state, *args, **kwargs):\n",
    "        # 输入 inputs 形状：(batch_size, num_steps)\n",
    "        # state 是包含 num_layers 个元素的列表，每个元素形状：(batch_size, 2*num_hiddens)\n",
    "        X = self.embedding(inputs) # 先进行词嵌入，形状：(batch_size, num_steps, embed_size)\n",
    "\n",
    "        # 用编码器最后一层隐藏状态构造上下文变量\n",
    "        context = state[-1] # 形状：(batch_size, 2*num_hiddens)\n",
    "        # 最后将 context 扩展到每个时间步，便于与输入 X 在特征维度上拼接\n",
    "        # context 的形状：(batch_size, num_steps, 2*num_hiddens)\n",
    "        context = tf.repeat(tf.expand_dims(context, axis=1), repeats=X.shape[1], axis=1)\n",
    "\n",
    "        # 将输入和上下文变量拼接\n",
    "        # X_and_context 的形状：(batch_size, num_steps, embed_size + 2*num_hiddens)\n",
    "        X_and_context = tf.concat([X, context], axis=-1)\n",
    "\n",
    "        # 依次计算每一层 RNN\n",
    "        for i,layer in enumerate(self.rnn_layers):\n",
    "            # X_and_context 的形状：(batch_size, num_steps, 2*num_hiddens)\n",
    "            # X_and_context 在每层计算中相当于从 H^{(l)} 到 H^{(l+1)}\n",
    "            X_and_context, state[i] = layer(X_and_context, state[i], **kwargs)\n",
    "        \n",
    "        # 输出形状：(batch_size, num_steps, vocab_size)\n",
    "        output = self.dense(X_and_context)\n",
    "        return output, state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来测试解码器的工作接口是否正常，并观察它的输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意 num_hiddens 和 num_layers 需要与编码器一致\n",
    "# 如果编码器是双向 RNN，则解码器 num_hiddens 需要乘以 2\n",
    "decoder = ch4.Seq2SeqDecoder(vocab_size=vocab_size, embed_size=embed_size,\n",
    "                             num_hiddens=2*num_hiddens, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状： (4, 7, 10)\n",
      "解码器 RNN 层数： 2\n",
      "第一层隐藏状态形状： (4, 32)\n"
     ]
    }
   ],
   "source": [
    "# 用编码器的输出初始化解码器的隐藏状态\n",
    "state = decoder.init_state(encoder(X))\n",
    "\n",
    "# 推理和计算\n",
    "output, state = decoder(X, state, training=False)\n",
    "\n",
    "print(\"输出形状：\", output.shape) # (batch_size, num_steps, vocab_size)\n",
    "print(\"解码器 RNN 层数：\", len(state)) # num_layers\n",
    "print(\"第一层隐藏状态形状：\", state[0].shape) # (batch_size, 2*num_hiddens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，在上面的例子中，我们让**编码器和解码器使用了相同的** `vocab_size` 和 `embed_size`，事实上，编码器和解码器分别处源语言和目标语言\n",
    "* 它们**应该有不同的词表大小**\n",
    "* 也可以**选择不同的词嵌入维度**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，下图总结了 RNN 实现**编码器-解码器**模型的计算结构："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/RNN实现编码器解码器模型.svg\" width=500>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们讨论有关**模型训练和预测**相关的计算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 损失函数**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 `<bos>` 开始，在每个时间步，**解码器预测了输出词元的概率分布**，类似于语言模型，通过**计算交叉熵损失函数来进行优化**，但直接计算会存在问题：\n",
    "* 在训练数据生成过程中，我们强制**通过填充和截断把子序列变换到相同长度**，因此一些子序列的末尾是填充词 `<pad>`，我们**应该将填充词元的预测排除在损失函数的计算之外**\n",
    "* 我们可以定义一个 `sequence_mask` 函数，通过**零值化来屏蔽不相关的项**（即去除掉填充的部分），以便后面**任何不相关预测的计算都是与零的乘积**，结果都等于零\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在序列中屏蔽不相关的项\n",
    "def sequence_mask(X : tf.Tensor, valid_len : tf.Tensor, value : float = 0):\n",
    "    # X 形状：(batch_size, num_steps) 或者 (batch_size, num_steps, p)\n",
    "    # valid_len 形状：(batch_size,)\n",
    "    maxlen = X.shape[1] # 序列长度\n",
    "    \n",
    "    # lens 生成从 0 到 maxlen-1 的序列\n",
    "    lens = tf.range(start=0, limit=maxlen, dtype=tf.float32)[None, :] # 形状：(1, num_steps)\n",
    "    # valid_len[:, None] 将 valid_len 的形状变换为 (batch_size, 1)\n",
    "    valid_len = tf.cast(valid_len[:, None], dtype=tf.float32) # 形状：(batch_size, 1)\n",
    "    # 利用广播机制生成掩码 mask，形状：(batch_size, num_steps)\n",
    "    # mask[i, j] = 1 if lens[j] < valid_len[i]; 0 otherwise\n",
    "    mask = lens < valid_len\n",
    "    \n",
    "    # 分两种情况，将 mask 为 0 的元素替换为 value\n",
    "    # 1. X 是一个三维张量，形状 (batch_size, num_steps, p)\n",
    "    # 需要把 mask 也变成三维张量，形状 (batch_size, num_steps, 1)\n",
    "    if len(X.shape) == 3:\n",
    "        return tf.where(tf.expand_dims(mask, axis=-1), X, value)\n",
    "    # 2. X 是一个二维张量，形状 (batch_size, num_steps)\n",
    "    # 则保持 mask 是一个二维张量\n",
    "    else:\n",
    "        return tf.where(mask, X, value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequence_mask()` 已经被写入 `../source/code/utils.py` 中"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来测试一下函数的计算效果，可以看到**超出** `valid_len` **长度的部分被 mask 为零**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [4, 5, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 二维张量输入\n",
    "X = tf.constant([[1, 2, 3], \n",
    "                 [4, 5, 6]])\n",
    "utils.sequence_mask(X, valid_len=tf.constant([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三维张量输入\n",
    "X = tf.ones((2,3,4))\n",
    "utils.sequence_mask(X, valid_len=tf.constant([1, 2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们可以通过扩展softmax交叉熵损失函数来遮蔽不相关的预测\n",
    "* 最初，所有预测词元的掩码 mask 都设置为 1\n",
    "* 一旦给定了**有效长度** `valid_len`，**与填充词元对应的掩码将被设置为 0**\n",
    "* 最后，**将所有词元的损失乘以掩码**，以过滤掉损失中填充词元产生的不相关预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, valid_len, **kwargs):\n",
    "        # 初始化父类参数 reduction='none'，表示不对损失求均值\n",
    "        super().__init__(reduction='none',**kwargs)\n",
    "        self.valid_len = valid_len\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_true 形状：(batch_size, num_steps)\n",
    "        # y_pred 形状：(batch_size, num_steps, vocab_size)\n",
    "        # 初始化权重，形状：(batch_size, num_steps)\n",
    "        weights = tf.ones_like(y_true, dtype=tf.float32)\n",
    "        # 通过 sequence_mask 函数将不相关项的权重设为 0\n",
    "        weights = utils.sequence_mask(weights, self.valid_len)\n",
    "\n",
    "        # 计算无掩码的交叉熵损失\n",
    "        loss_func = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
    "        unweighted_loss = loss_func(y_true, y_pred) # 形状：(batch_size, num_steps)\n",
    "\n",
    "        # 将不相关项的损失也设为 0\n",
    "        # 为了演示，我们这里仅对时间步聚合，保留批量大小维度\n",
    "        weighted_loss = tf.reduce_mean((unweighted_loss*weights), axis=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MaskedSoftmaxCELoss` 已经被写入 `../source/code/utils.py` 中"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来**检查损失函数的工作是否正确**，可以看到 `valid_len = 0` 的批量，**对应的损失为零**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.7980366, 0.6846905, 0.       ], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 3, num_steps = 4, vocab_size = 5\n",
    "y_pred = tf.random.uniform((3,4,5))\n",
    "y_true = tf.zeros((3,4), dtype=tf.int32)\n",
    "\n",
    "# 有效长度\n",
    "valid_len = tf.constant([4, 2, 0])\n",
    "loss = utils.MaskedSoftmaxCELoss(valid_len)\n",
    "loss(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) 模型训练**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的循环训练过程注意：\n",
    "* 特定的**序列开始词元** `<bos>` 是和**原始的输出序列**（不包括序列的结束词 `<eos>`）拼接在一起作为解码器的输入，这样子相当于将 $y_1,y_2,\\cdots,y_{T'}$ **右移一位**，在 $t'$ 时刻，模型的输入是 $y_{t'-1}$，然后预测 $y_{t'}$\n",
    "    * 即观测到 `<bos>` 要预测 $y_1$，观测到 $y_1$ 时需要预测 $y_2$，以此类推\n",
    "    * 这被称为**强制教学**，因为原始的正确输出序列（即标签数据）被送入解码器作为输入，而**真实情况下，我们只可能将来自上一步的预测值作为解码器下一步的输入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(model, data_iter, tgt_vocab, Epochs : int=100, lr : float=0.01, verbose : int=1):\n",
    "    # 初始化优化器\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    animator = utils.Animator(xlabel='epoch', ylabel='loss',\n",
    "                              xlim=[1, Epochs], legend=['train'])\n",
    "\n",
    "    # 存储每个迭代周期的损失和样本量\n",
    "    loss_batch, samples_batch = 0, 0\n",
    "    # 记录单词处理速度\n",
    "    speeds = []\n",
    "\n",
    "    for epoch in range(Epochs):\n",
    "        start = time.time() # 计时开始\n",
    "        for batch in data_iter:\n",
    "            # 分别拿到四个元素：编码器输入、编码器输入有效长度、解码器输入、解码器输入有效长度\n",
    "            # X, Y 形状：(batch_size, num_steps)\n",
    "            # X_valid_len, Y_valid_len 形状：(batch_size,)\n",
    "            X, X_valid_len, Y, Y_valid_len = batch\n",
    "            # 为解码器的输入添加 <bos>，形状：(batch_size, 1)\n",
    "            bos = tf.reshape(tf.constant([tgt_vocab['<bos>']]*Y.shape[0]), (-1, 1))\n",
    "            # 去掉解码器输入的最后一个时间步，在开头加上 <bos>，保持形状不变\n",
    "            dec_input = tf.concat([bos, Y[:, :-1]], axis=1)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # 进行预测，计算损失\n",
    "                # 注意我们将 X_valid_len 传入给模型，它作为 *args 的一部分\n",
    "                # 但目前我们的模型并没有使用它，这在后续章节中会改变\n",
    "                Y_hat, _ = model(X, dec_input, X_valid_len, training=True)\n",
    "                loss_func = utils.MaskedSoftmaxCELoss(Y_valid_len)\n",
    "                loss = loss_func(Y, Y_hat) # 形状：(batch_size,)\n",
    "            weights = model.trainable_variables\n",
    "            grads = tape.gradient(loss, weights)\n",
    "            grads = utils.grad_clipping(grads, 1) # 梯度裁剪\n",
    "            optimizer.apply_gradients(zip(grads, weights))\n",
    "\n",
    "            # 将该批量的损失函数值加到总损失函数值上\n",
    "            num_tokens = tf.reduce_sum(Y_valid_len).numpy()\n",
    "            loss_batch += tf.reduce_sum(loss).numpy()\n",
    "            samples_batch += num_tokens\n",
    "        \n",
    "        end = time.time() # 计时结束\n",
    "        speeds.append(samples_batch / (end - start))\n",
    "\n",
    "        if epoch == 0 or (epoch + 1) % verbose == 0:\n",
    "            # 计算困惑都\n",
    "            ce = tf.math.exp(loss_batch / samples_batch).numpy()\n",
    "            animator.add(epoch + 1, [ce])\n",
    "    \n",
    "    print(f\"平均 {np.mean(speeds):.1f} 词元/秒\")\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练函数 `train_seq2seq` 已经写入 `../source/code/utils.py` 中"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入相关的数据集，设置相关的超参数，创建模型并训练模型\n",
    "* 根据 4.4.1 节的探索，大部分**翻译文本的序列长度在 20 左右**，我们设置 `num_steps = 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322275/322275 [01:22<00:00, 3885.84it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 64, 64, 2, 0.25\n",
    "batch_size, num_steps = 512, 20\n",
    "\n",
    "# 读取数据\n",
    "train_iter, src_vocab, tgt_vocab = ch4.load_translation_en_zh(\n",
    "    file=\"../source/data/translation/news_v16-en-zh.tsv\",\n",
    "    batch_size=batch_size, num_steps=num_steps)\n",
    "\n",
    "# 创建编码器-解码器模型\n",
    "encoder = ch4.Seq2SeqEncoder(vocab_size=len(src_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "decoder = ch4.Seq2SeqDecoder(vocab_size=len(tgt_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=2*num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "model = utils.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 4198060.0 词元/秒\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = utils.train_seq2seq(model, train_iter, tgt_vocab, Epochs=100, lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练这个模型花费了很大的力气，我们可以**保存该模型**，保存模型的方法有很多种，这里介绍**通过参数保存模型的方法**\n",
    "* 我们将模型的参数保存为文件\n",
    "* 下次再创建相同结构的一个模型时。只需要从本地加载参数文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A) 模型保存**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过模型实例的方法 `model.save_weights()` 就可以保存模型参数了，一般我们会将参数保存为 `.h5` 文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 保存模型参数\n",
    "model.save_weights(\"../source/model/ch4_translation_en_zh.h5\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B) 模型读取**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的读取部分稍微复杂一些，大致可以分为下面三个部分：\n",
    "* 创建一个**新的相同的模型实例** `model`，需要**保证网络结构相同**（隐藏层数量，隐藏神经元大小等）\n",
    "* `Tensorflow` 使用了**延后初始化策略**，即**模型实例化后，参数并未进行初始化**，在第一次调用模型时，才会初始化参数\n",
    "    * 因此我们可以**生成符合模型输入要求的随机数据，调用一次模型，初始化模型参数**\n",
    "* 通过 `model.load_weights()` 加载保存的模型参数文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成随机输入，调用一次模型，初始化模型\n",
    "X = tf.zeros((1, 1), dtype=tf.int32)\n",
    "Y = model(X, X, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型参数\n",
    "model.load_weights(\"../source/model/ch4_translation_en_zh.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 第一步，创建相同结构的模型\n",
    "encoder = ch4.Seq2SeqEncoder(vocab_size=len(src_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "decoder = ch4.Seq2SeqDecoder(vocab_size=len(tgt_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=2*num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "model = utils.EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# 第二步，生成随机输入，调用一次模型，初始化模型\n",
    "X = tf.zeros((1, 1), dtype=tf.int32)\n",
    "Y = model(X, X, training=False)\n",
    "\n",
    "# 第三步，加载模型参数\n",
    "model.load_weights(\"../source/model/ch4_translation_en_zh.h5\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5) 模型预测**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了采用**一个接着一个词元的方式预测输出序列**，每个解码器当前时间步的输入都**将来自于前一时间步的预测词元**\n",
    "* 与训练类似，序列的**开始词元** `<bos>` **在初始时间步放入到解码器中**\n",
    "* 当预测得到 `<eos>` 时，模型的预测结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(model, src_sentence : str, src_vocab, tgt_vocab, \n",
    "                    num_preds : int, num_steps : int, save_attention_weights : bool=False):\n",
    "    \"\"\"\n",
    "    save_attention_weights : bool\n",
    "        是否保存注意力权重，这在下一章的注意力机制中会用到\n",
    "    \"\"\"\n",
    "    # 将源语句按词元切分\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    # 句子的有效长度\n",
    "    enc_valid_len = tf.constant([len(src_tokens)])\n",
    "    # 进行截断和填充\n",
    "    src_tokens = ch4.truncate_padding(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = tf.expand_dims(tf.constant(src_tokens), axis=0) # 添加批量大小维度\n",
    "\n",
    "    # 编码器输出，初始化解码器隐藏状态\n",
    "    enc_outputs = model.encoder(enc_X, enc_valid_len, training=False)\n",
    "    dec_state = model.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "\n",
    "    # 解码器的初始输入，添加批量大小维度\n",
    "    dec_X = tf.expand_dims(tf.constant([tgt_vocab['<bos>']]), axis=0)\n",
    "    output_seq, attention_weights = [], [] # 初始化输出序列和注意力权重\n",
    "    for _ in range(num_preds):\n",
    "        # 依次生成一个词元，更新解码器的隐藏状态\n",
    "        # Y 的形状：(1, 1, vocab_size)\n",
    "        Y, dec_state = model.decoder(dec_X, dec_state, training=False)\n",
    "        # 从概率分布中获取词元\n",
    "        dec_X = tf.argmax(Y, axis=2) # 形状：(1, 1)\n",
    "        pred = dec_X[0][0].numpy()\n",
    "\n",
    "        # 保存注意力权重\n",
    "        if save_attention_weights:\n",
    "            attention_weights.append(model.decoder.attention_weights)\n",
    "        \n",
    "        # 遇到 <eos> 结束预测\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred) # 添加到输出序列\n",
    "    return \"\".join(tgt_vocab.to_tokens(output_seq)), attention_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数 `predict_seq2seq()` 已经写入 `../source/code/utils.py` 了，便于后续章节使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文：how are you ?\n",
      "中文：你如何？\n",
      "英文：peace is what we want .\n",
      "中文：和平是我们的希望。\n",
      "英文：he is my teacher and he teaches english .\n",
      "中文：他是我的老师，他的作品是\n",
      "英文：the chinese law prohibits citizens from drug trafficking .\n",
      "中文：中国禁止中国的非法毒品和毒品走私。\n"
     ]
    }
   ],
   "source": [
    "engs = [\"how are you ?\", \n",
    "        \"peace is what we want .\", \n",
    "        \"he is my teacher and he teaches english .\",\n",
    "        \"the chinese law prohibits citizens from drug trafficking .\"]\n",
    "for eng in engs:\n",
    "    print(f\"英文：{eng}\")\n",
    "    print(f\"中文：{utils.predict_seq2seq(model, eng, src_vocab, tgt_vocab, num_steps=10, num_preds=10)[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型的翻译效果不理想，但基本单词的翻译是正确的**\n",
    "* 后续章节我们会逐步解析 RNN 模型存在的问题，并改进这个结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于机器翻译任务，如何**评估翻译质量的好坏呢**，一种常用的方法是计算指标**BLEU**（bilingual evaluation understudy）\n",
    "* BLEU 最先用于评估机器翻译任务，但现在它已经被广泛用于**测量许多应用的输出序列的质量**\n",
    "* 原则上说，对于预测序列中的任意 n-gram 语法，BLEU 评估**这个语法是否出现在标签序列中**：\n",
    "$$\n",
    "\\text{BLEU} = \\exp\\left( \\min\\left( 0, 1 - \\frac{\\text{len}_{\\text{label}}}{\\text{len}_{\\text{pred}}} \\right) \\right)\\prod_{n=1}^{k} p_n^{1/2^n}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\text{len}_{\\text{label}}, \\text{len}_{\\text{pred}}$ 是标签词元数和预测词元数\n",
    "* $k$ 控制用于匹配的最长 n-gram 语法\n",
    "* $p_n$ 表示 n-gram 语法的精确度，它是两个数量的比值\n",
    "    * 分子是预测序列与标签序列中，匹配的 n-gram 语法的数量\n",
    "    * 分母是预测序列中 n-gram 语法的数量\n",
    "    * 比如给定标签序列 `A,B,C,D,E,F` 和预测序列 `A,B,B,C,D`，则\n",
    "        * $n=1, p_1 = 4/5$，预测序列 1-gram 包含 `A,B,B,C,D` 共 5 个，标签中 `A,B,C,D` 共 4 个能匹配上\n",
    "        * $n=2, p_2 = 3/4$，预测序列 2-gram 包含 `AB,BB,BC,CD` 共 4 个，标签中 `AB, BC, CD` 共 3 个能匹配上\n",
    "        * $n=3, p_3 = 1/3$，预测序列 3-gram 包含 `ABB,BBC,BCD` 共 3 个，标签中 `BCD` 共 1 个能匹配上\n",
    "        * $n=4, p_4 = 0$，预测序列 4-gram 包含 `ABBC,BBCD` 共 2 个，标签中没有能匹配上的 4-gram 语法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据 BLEU 的定义，**当预测序列与标签序列完全相同时，BLEU 的值为 1**\n",
    "* 由于 **n-gram 语法越长匹配难度越大**，因此 BLEU 为**更长的 n-gram 语法的精确度分配了更大的权重**，当 $p_n$ 固定时，$p_n^{1/2^n}$ 会随着 $n$ 的增长而增加，相当于给予更多的奖励\n",
    "* 由于预测的序列越短获得的 $p_n$ 值越高，所以 **BLEU 累乘项之前的系数用于惩罚较短的预测序列**\n",
    "    * 例如 $k=2$ 时，标签序列为 `A,B,C,D,E,F`，预测序列为 `A,B`，则 $p_1=p_2 = 1$，但乘法因子 $\\exp(1 - 3)\\approx 0.14$ 会极大的降低 BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_bleu(label_seq : str, pred_seq : str, k : int):\n",
    "    # 词元化\n",
    "    import jieba, math, collections\n",
    "    label_tokens, pred_tokens = list(jieba.cut(label_seq)), list(jieba.cut(pred_seq))\n",
    "    # 序列长度\n",
    "    label_len, pred_len = len(label_tokens), len(pred_tokens)\n",
    "    \n",
    "    # 初始化 BLEU 分数\n",
    "    score = math.exp(min(0, 1 - label_len / pred_len)) # 惩罚项\n",
    "    \n",
    "    for n in range(1, k+1):\n",
    "        num_matches = 0 # 匹配上的 n-gram 个数\n",
    "        label_subs = collections.defaultdict(int) # 统计 label_tokens 中 n-gram 语法\n",
    "        for i in range(label_len - n + 1):\n",
    "            label_subs[''.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(pred_len - n + 1):\n",
    "            pred_sub = ''.join(pred_tokens[i: i + n]) # 选取 n-gram 语法\n",
    "            # 在标签中匹配上了 n-gram 语法\n",
    "            if label_subs[pred_sub] > 0:\n",
    "                num_matches += 1 # 匹配上的 n-gram 个数加 1\n",
    "                label_subs[pred_sub] -= 1 # 减去已经匹配上的 n-gram 语法\n",
    "        # 计算 BLEU\n",
    "        score *= math.pow(num_matches / (pred_len - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数 `chinese_bleu()` 已经写入 `../source/code/utils.py` 了，便于我们后续章节使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you ? \n",
      "=> 你如何？, bleu 1.000\n",
      "peace is what we want . \n",
      "=> 和平是我们的希望。, bleu 0.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he is my teacher and he teaches english . \n",
      "=> 他是我的老师，他的作品是, bleu 0.669\n",
      "the chinese law prohibits citizens from drug trafficking . \n",
      "=> 中国禁止中国的非法毒品和毒品走私。, bleu 0.396\n"
     ]
    }
   ],
   "source": [
    "# 句子对\n",
    "pairs = [[\"how are you ?\", \"你如何？\",],\n",
    "         [\"peace is what we want .\", \"和平是我们所希望的。\",],\n",
    "         [\"he is my teacher and he teaches english .\", \"他是我的老师，他教英语\",],\n",
    "         [\"the chinese law prohibits citizens from drug trafficking .\", \"中国法律禁止公民毒品走私。\"]]\n",
    "# 评估模型\n",
    "for en, zh in pairs:\n",
    "    trans, _ = utils.predict_seq2seq(model, en, src_vocab, tgt_vocab, num_steps=10, num_preds=10)\n",
    "    bleu = utils.chinese_bleu(zh, trans, k=2)\n",
    "    print(f\"{en} \\n=> {trans}, bleu {bleu:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5.4 束搜索**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们介绍一种**语言模型预测的采样方法**，这可以让我们对相同的输入获得不同的预测输出结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前所有语言模型的预测过程中，我们都采用**贪心预测**的想法，即在每个时间步的预测，都选取**下一个词概率分布的最大值点**，直到到达指定的预测词数 `num_preds` 或者预测出 `<eos>`：\n",
    "$$\n",
    "y_{t'} = \\mathop{\\arg\\max}\\limits_{y\\in\\mathcal{Y}} P(y|y_1,\\cdots,y_{t'-1},c)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们有四个词元 `A, B, C, <eos>`，考虑四个时间步的预测，则预测输出过程如下图所示："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/贪心预测.svg\" width=300>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以直接计算**贪心预测**得到的输出序列的概率为：\n",
    "$$\n",
    "P(y_1,y_2,y_3,y_4) = 0.5\\times 0.4\\times 0.4\\times 0.6 = 0.048\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很显然，**贪心策略并不一定能取得关于整个序列的最优预测**，例如选取下面的预测结果，此时输出序列的概率为：\n",
    "$$\n",
    "P(y_1,y_2,y_3,y_4) = 0.5\\times 0.3\\times 0.6\\times 0.6 = 0.054 > 0.048\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/贪心预测失效.svg\" width=300>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此我们可以认为，序列 `ACB` 出现的可能性要比 `ABC` 更高，它应该是更优的输出序列\n",
    "* 注意**下一个时间步的词元的概率分布会依赖于之前预测选择的结果**\n",
    "    * 例如当我们在 $t=2$ 时选择预测词元 `C` 后，时间步 $t=3,4$ 的词元概率分布发生了改变\n",
    "* 新序列 `ACB` 在**第二步选择了一个次优的词元**，却在整体上帮我们获得了更优的序列，这是**贪心算法做不到的**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么如何获得潜在的更优的预测序列呢？一种最直观的想法是**穷举搜索**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们**穷举地列举所有可能的输出序列及其条件概率**，然后将所有可能输出序列的概率排序，就可以得到最优质的预测序列\n",
    "* 假设输出词表大小为 $|\\mathcal{Y}|$，预测时间步为 $T'$，则穷举法的计算量为 $\\mathcal{O}(|\\mathcal{Y}|^{T'})$\n",
    "* 当 $|\\mathcal{Y}| = 10000$，$T' = 10$，我们需要评估 $10000^{10} = 10^{40}$ 个序列，这个**计算量是不可能实现的**\n",
    "* 而**贪心搜索的评估量只有** $|\\mathcal{Y}|\\times T'$，因为只需要在每个时间步对 $|\\mathcal{Y}|$ 个可能的输出选择最优即可"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了穷举搜索外，一种可行的搜索方法是**束搜索**（**Beam Search**），它是贪心搜索的一个改进版本\n",
    "* 束搜索包含一个**超参数**，名为**束宽** $k$\n",
    "* 在时间步 $t=1$，我们**选择具有最高条件概率的** $k$ 个词元，这 $k$ 个词元分别是 $k$ 个候选输出序列的第一个词元\n",
    "* 在随后的每个时间步 $t$，基于上一个时间步 $t-1$ 的 $k$ 个候选输出序列，我们将继续**从** $k\\cdot |\\mathcal{Y}|$ **个可能的选择中**，**挑选出最高条件概率的** $k$ **个候选输出序列**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 $k=2$ 时，束搜索如下进行：\n",
    "* 在 $t = 1$ 时，假设具有最高条件概率 $P(y_1|c)$ 的词元是 $A,C$\n",
    "* 在 $t = 2$ 时，我们计算下面 $2|\\mathcal{Y}|$ 个条件概率：\n",
    "    $$\n",
    "    P(A,y_2|c) = P(A|c)\\cdot P(y_2|A,c),\\quad y_2\\in\\mathcal{Y} \\\\\n",
    "    P(C,y_2|c) = P(C|c)\\cdot P(y_2|C,c),\\quad y_2\\in\\mathcal{Y} \\\\\n",
    "    $$\n",
    "    然后从 $2|\\mathcal{Y}|$ 个条件概率中，**选择最大的两个**，例如 $P(A,B|c),P(C,E|c)$\n",
    "* 在 $t = 3$ 时，继续计算下面 $2|\\mathcal{Y}|$ 个条件概率：\n",
    "    $$\n",
    "    P(A,B,y_3|c) = P(A,B|c)\\cdot P(y_3|A,B,c),\\quad y_2\\in\\mathcal{Y} \\\\\n",
    "    P(C,E,y_3|c) = P(C,E|c)\\cdot P(y_3|C,E,c),\\quad y_2\\in\\mathcal{Y} \\\\\n",
    "    $$\n",
    "    然后从 $2|\\mathcal{Y}|$ 个条件概率中，**选择最大的两个**，例如 $P(A,B,D|c),P(C,E,D|c)$\n",
    "* 示意图如下："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../source/Chap4/束搜索.svg\" width=800>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以将得到的 $k$ 个候选输出**都认为是理想的输出预测**，然后输出从中随机抽取一个\n",
    "* 因此有的语言模型每次给定相同的输入，模型的输出可能会不太一样\n",
    "* 对于 $k$ 个候选序列，因为序列生成到 `<eos>` 就停止，因此 $k$ 个**序列长度可能不一样**\n",
    "* 我们也可以计算 $k$ 个**候选序列输出条件概率的最大值**，作为**最优序列**输出：\n",
    "    $$\n",
    "    \\frac{1}{L^a} \\log P(y_1,\\cdots,y_L|c) = \\frac{1}{L^a}\\sum_{t'=1}^{L} \\log P(y_{t'}|y_1,\\cdots,y_{t'-1},c)\n",
    "    $$\n",
    "    其中 $L$ 是候选序列的长度，$a$ 通常取 $a = 0.75$，因为一个较长的序列在求和中会有更多的对数项，因此**分母** $L^a$ **用于惩罚长序列**\n",
    "* 束搜索的计算量是 $\\mathcal{O}(k|\\mathcal{Y}|T')$，这个结果介于**贪心策略和穷举策略**之间，事实上，**贪心策略等价于束宽** $k=1$ **的特殊类型的束搜索**，束搜索可以**调整** $k$ **在正确率和计算代价之间进行权衡**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "束搜索的实现留作习题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **练习**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 按照束搜索的逻辑，实现机器翻译任务的束搜索预测函数 `beam_search_predict_seq2seq()`\n",
    "    1. 思考，**束搜索能用于前面章节的文本预测任务吗**？\n",
    "    2. 从 `../source/model/ch4_translation_en_zh.h5` 加载训练好的模型，提供英文源语句给模型，设置束宽为5，每次给出 5 个可能的翻译结果，**测试束搜索的预测效果**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提示**，你可以按如下方式，通过**加载参数文件**导入 `Tensorflow` 的模型\n",
    "\n",
    "```python\n",
    "# 创建模型\n",
    "embed_size, num_hiddens, num_layers, dropout = 64, 64, 2, 0.25\n",
    "batch_size, num_steps = 512, 20\n",
    "\n",
    "# 读取数据\n",
    "train_iter, src_vocab, tgt_vocab = ch4.load_translation_en_zh(\n",
    "    file=\"../source/data/translation/news_v16-en-zh.tsv\",\n",
    "    batch_size=batch_size, num_steps=num_steps)\n",
    "\n",
    "# 创建编码器-解码器模型\n",
    "encoder = ch4.Seq2SeqEncoder(vocab_size=len(src_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "decoder = ch4.Seq2SeqDecoder(vocab_size=len(tgt_vocab), embed_size=embed_size, \n",
    "                             num_hiddens=2*num_hiddens, num_layers=num_layers, dropout=dropout)\n",
    "model = utils.EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# Tensorflow采用延后初始化\n",
    "# 只有调用一次模型后，模型参数才会被初始化\n",
    "X = tf.zeros((1,1))\n",
    "Y = model(X, X)\n",
    "\n",
    "# 加载模型参数\n",
    "model.load_weights(\"../source/model/ch4_translation_en_zg.h5\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 让我们用所学到的 RNN 模型处理另一种 NLP 任务，**文本分类**，请按照如下顺序完成任务\n",
    "    1. 首先，我们需要**导入数据集**，并准备训练模型输入相关的流水线\n",
    "        1. 我们使用 `Tensorflow` 提供的 **IMDB 电影评论数据集**，通过 `TFDS` 导入，数据集中**每条文本序列对应一个二分类标签，1 表示文本内容是积极的，0 表示文本内容是消极的**\n",
    "            ```python\n",
    "            import tensorflow_datasets as tfds\n",
    "\n",
    "            # 导入数据集\n",
    "            dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "            train_ds, test_ds = dataset['train'], dataset['test'] # 获取训练集和测试集\n",
    "            ```\n",
    "        2. `TFDS` 返回的 `info` 包含了文本的编码器 `encoder`，它可以将英文字符串文本编码为词元索引\n",
    "            ```python\n",
    "            encoder = info.features['text'].encoder # 取出文本编码器\n",
    "            print(\"词表大小：\",encoder.vocab_size)\n",
    "\n",
    "            string = \"Hello Tensorflow.\"\n",
    "            encoded_str = encoder.encode(string) # 将文本编码为词元索引\n",
    "            decoded_str = encoder.decode(encoded_str) # 也可以将词元索引恢复到文本\n",
    "\n",
    "            print(\"编码后词元索引：\",encoded_str)\n",
    "            print(\"解码后恢复的字符串：\",decoded_str)\n",
    "            ```\n",
    "        3. `Tensorflow` 的 `TFDS` 提供的数据集接口自带了填充功能，设置超参数，`padded_batch()` 会将**每个批次的序列填充至批次中最长文本的长度**，因此 `padded_batch()` 所提供的**每个批量的文本序列时间步是不固定的**\n",
    "            ```python\n",
    "            buffer_size, batch_size = 10000, 64 # 设置缓冲区大小和批量大小\n",
    "            \n",
    "            # 设置填充和批量大小\n",
    "            train_ds = train_ds.shuffle(buffer_size).padded_batch(batch_size)\n",
    "            test_ds = test_ds.padded_batch(batch_size)\n",
    "            ```\n",
    "        4. 你可以尝试从 `train_ds` 或者 `test_ds` 中读取批量，来观察每个批量的数据\n",
    "            ```python\n",
    "            # 读取批量\n",
    "            for x_batch, y_batch in train_ds:\n",
    "                break\n",
    "            ```\n",
    "    2. 现在，我们来**搭建一个二分类模型来实现情感分类**\n",
    "        1. 模型应该具有一个嵌入层，来将词元嵌入到词向量空间\n",
    "        2. 设计你的 **RNN 层来提取文本序列的特征**，你可以考虑如下方面：\n",
    "            1. 使用何种 RNN 模型？\n",
    "            2. 是否使用双向 RNN 模型？\n",
    "            3. 是否使用多层 RNN 模型？\n",
    "            4. 应该用何种方式实现模型？`Sequential` 简洁实现，还是自定义继承 `tf.keras.Model` 类\n",
    "            5. 模型的超参数应该如何设置？\n",
    "        3. 设计模型后续的**输出层**，构建**二分类模型**，用于判断文本的积极/ 消极情绪\n",
    "    3. 进行模型训练，绘制模型在**训练集上和测试集上的损失函数和准确率随迭代次数曲线**\n",
    "        1. 考虑如何训练模型，你可以定义自己的训练函数\n",
    "        2. 如果你使用了 `Sequential` 方法定义模型，那么利用 `model.compile()` 和 `model.fit()` 能够帮助你更快设置模型的训练\n",
    "        3. 模型的在训练集和测试集上的准确率是多少？你的模型**出现了过拟合吗**？\n",
    "    4. 定义模型**对单个样本的预测函数**，当给定一条文本序列时，函数能输出该文本的情绪是积极还是消极的"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 在进入下一章之前，我们讨论 RNN 存在的问题和局限\n",
    "    1. 从实验可以发现，RNN 参数比 CNN 少，训练速度却更慢，尤其是针对**长序列**，在下一章中我们会介绍**模型处理输入的并行度**的概念，在此之前，依靠直觉和你的理解尝试**解释 RNN 训练速度慢的原因**\n",
    "    2. 即使使用了有记忆机制的 `GRU` 和 `LSTM`，对处理复杂的长序列时，**RNN 模型依然有些捉襟见肘**，联系 CNN 感受野的概念，我们也可以为 RNN 定义\"感受野\"，尝试解释**为什么 RNN 处理长序列时效果不理想**？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
